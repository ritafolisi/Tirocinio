\documentclass{article}
\usepackage{cite}
\usepackage[italian]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{cases}
\usepackage{braket}
\usepackage{pdfpages}
\usepackage{multirow}
\DeclarePairedDelimiter{\norma}{\lVert}{\rVert}
\graphicspath{{./images/}}
\bibliographystyle{unsrt}
\title{Elaborato finale}
\date{27-07-2020}
\author{Alessia Lombarda}

\begin{document}
	\begin{titlepage}
		\includepdf{images/FRONTESPIZIO.pdf}
	\end{titlepage}
	
	\pagenumbering{gobble}
	\tableofcontents
	%\listoffigures
	%\listoftables
	\newpage
	\pagenumbering{arabic}
	\section{Introduzione}
	%Prova~\cite{key1:key2}
	\section{Apprendimento supervisionato e induzione di insiemi fuzzy}
	\subsection{Apprendimento supervisionato}
	L'apprendimento automatico è una branca dell'intelligenza artificiale che studia algoritmi che utilizzano l'esperienza per migliorare la propria performance o per fare predizioni più accurate, dove con esperienza intendiamo l'informazione passata disponibile al sistema che apprende, tipicamente una collezione di dati resi disponibili all'analisi. Questi dati possono essere insiemi di informazioni a cui sono state abbinate manualmente delle etichette oppure dati estratti direttamente dall'ambiente: gli algoritmi avranno l'obiettivo di effettuare predizioni sulla base dei dati appresi.
	L'apprendimento automatico si applica a svariati campi; alcune delle classi principali di problemi di apprendimento sono:
	\begin{itemize}
		\item\textbf{Classificazione:} l'assegnamento di ogni elemento ad una categoria; in questo caso di solito il numero di classi possibili è ridotto
		\item\textbf{Regressione:} la predizione di un valore reale per ogni elemento nel set; in questo caso l'errore associato ad una predizione errata dipende della differenza tra il valore predetto e quello reale
		\item\textbf{Ranking:} l'ordinamento di elementi in base a un criterio definito a priori
		\item\textbf{Clustering:} il partizionamento di elementi in regioni omogenee
		\item\textbf{Riduzione della dimensionalità:} la trasformazione di un set di elementi in una rappresentazione degli stessi a meno dimensioni, preservando alcune proprietà degli oggetti iniziali
	\end{itemize}
	L'apprendimento automatico può essere \textit{supervisionato}, \textit{non supervisionato} o \textit{semi-supervisionato}; si tratterà la prima categoria di algoritmi.\\
	L'apprendimento supervisionato è uno dei tipi di apprendimento automatico che definisce gli algoritmi in cui il learner riceve un set di dati con etichette associate (\textit{training set}) per poi eseguire delle predizioni su dati non noti.\\
	L'algoritmo in questione dovrà quindi apprendere una funzione, $f$, che cercherà di approssimare al meglio con una funzione $h$, dove sia $f$ che $h$ sono funzioni di un vettore di input $X=(x_1,x_2,...,x_i,...,x_n)$ di $n$ componenti~\cite{bib:ml}.
	Nel caso di apprendimento supervisionato si conoscono quindi (a volte solo in modo approssimato) i valori di $f$ per gli $m$ elementi del training set, $\Xi$. Assumiamo che, se possiamo trovare una funzione $h$ che restituisce valori molto vicini a quelli di $f$ per gli elementi di $\Xi$, allora questa funzione costituisce una buona predizione per $f$, specialmente se $\Xi$ è grande.\\
	
	Per quanto riguarda il vettore di input $X$, questo può essere costituito da valori reali, discreti o categorici, che a loro volta possono essere ordinati (ad esempio \textit{\{small, medium, large\}}) o non ordinati; un caso a sè è l'uso di valori booleani, che può essere considerato un caso particolare dell'utilizzo di numeri discreti (1,0) o di variabili categoriche (\textit{True}, \textit{False}).\\
	L'output può essere invece un numero reale, ovvero una stima, oppure un valore categorico, tipico dei classificatori. Nel caso di output booleani, invece, possiamo distinguere \textit{istanze positive}, ovvero quelle con label 1, e \textit{istanze negative}, quelle con label 0; se anche l'input è booleano il classificatore implementa una \textit{funzione booleana}.\\
	
	Definiamo ora il \textit{bias}, ovvero un insieme di informazioni che devono essere note a priori affinché l'algoritmo approssimi correttamente la funzione $f$: perché ciò avvenga, bisogna infatti limitare l'insieme di possibili funzioni, tra cui poi l'algoritmo sceglierà la migliore.
	Se ad esempio si considera un algoritmo che deve approssimare una funzione booleana in $n$ variabili, si potranno avere $2^n$ possibili input. 
	\begin{figure}[h]
		\centering
		\subfloat[\emph{}]
		{\includegraphics[width=.45\textwidth]{nobias.png}} \quad
		\subfloat[\emph{}]
		{\includegraphics[width=.45\textwidth]{bias.png}} \\
		\caption{Relazione tra il numero di funzioni possibili e gli elementi del training set già esplorati in assenza e presenza di bias}
		\label{fig:bias}
		
	\end{figure}
	Si supponga di non avere bias, che sia $\mathcal{H}$ l'insieme delle $2^n$ possibili funzioni booleane e che non si abbiano preferenze tra quelle che danno corrispondenze sui dati del training set. In questo caso, dopo aver considerato un elemento del training set e la sua label si potrà suddividere a metà l'insieme delle funzioni, ovvero distinguere quelle che classificherebbero correttamente quell'elemento dalle restanti. Presentando via via più elementi del training set, ad ogni passo del processo si dimezza il numero di funzioni considerabili come ipotesi di approssimazione per $f$, come mostrato in Figura \ref{fig:bias}a. Non è possibile in questo caso generalizzare, perché i pattern già trovati non danno alcun indizio su quelli ancora da scoprire: è solo possibile memorizzare i primi, e ciò causa un apprendimento molto oneroso.\\
	Se invece si limitasse l'insieme $\mathcal{H}$ a un sottoinsieme $\mathcal{H}_c$, dipendentemente dal sottoinsieme e dall'ordine di presentazione dei dati del training set la curva che rappresenta il numero di possibili ipotesi di funzioni apparirebbe come in Figura~\ref{fig:bias}b: potrebbe infatti accadere che dopo aver visto meno di $2^n$ campioni si arrivi già a selezionare una funzione $h$ che ben approssimi $f$. L'introduzione del bias, quindi, ci permette di considerare solo alcune classi di funzioni, rendendo l'apprendimento più efficiente.\\
	
	L'algoritmo di apprendimento viene quindi addestrato sul \textit{training set} e successivamente valutato su un insieme distinto di dati, il \textit{test set}. Si dice che una funzione \textit{generalizza} se effettua predizioni perlopiù corrette sul test set.\\
	In questo contesto è anche necessario selezionare le features rilevanti da considerare per ogni campione, in quanto features significative possono guidare l'algoritmo di apprendimento correttamente, mentre altre povere di significato possono portare a significativi errori: prima di procedere con l'apprendimento è quindi necessario utilizzare un algoritmo di feature selection. \\
	Altra questione da considerare e gestire è la possibile presenza di rumore nei vettori del training set: possiamo distinguere il \textit{rumore di classe}, che altera il valore della funzione $f$, e quello di attributo, che altera in modo causale i valori del vettore di input $X$, rendendo imprecisa la corrispondenza tra i valori di input e quelli della funzione applicata su di essi.\\
	
	Fondamentale è poi la definizione di un metodo per la valutazione della performance dell'algoritmo: consideriamo a questo scopo l'\textit{accuratezza} e le \textit{funzioni di errore}. L'accuratezza consiste nel conteggiare il numero di predizioni corrette, e dividere questo valore per il la cardinalità del set di dati: si otterrà un valore compreso tra 0 e 1, che sarà maggiore se l'algoritmo predice in modo corretto. Uno stimatore più robusto è invece l'\textit{errore quadratico medio}, che si vuole minimizzare e rappresenta il rapporto tra la varianza entro i gruppi e la numerosità totale:\\
	\[
	MSE={1\over n}\sum_{i=1}^n (y_i-h(x_i))^2
	\]
	dove $y_i$ è la label attesa e $h(x_i)$ quella predetta dall'algoritmo, e la sua radice quadrata, l'RMSE:\\
	\[
	RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_{i} - h(x_{i}))^{2}}
	\]\\

	Per migliorare la performance dell'algoritmo ed evitare che questo si specializzi sui dati (\textit{overfitting}), è necessario svolgere una fase di training accurata; a causa della ridotta dimensione del training set disponibile, solitamente si è soliti usare una tecnica nota come \textit{n-fold cross validation}, usata sia per la model selection (la selezione dei parametri liberi dell'algoritmo), sia per la fase di training.
	
	Approfondiamo inizialmente l'uso della n-fold cross validation per la fase di model selection~\cite{bib:cv}: detto $\theta$ il vettore dei parametri liberi dell'algoritmo, per un fissato valore di $\theta$ si partiziona in modo causale un set $S$ di $m$ elementi con label associate in $n$ sottogruppi, o fold. L'i-esimo fold sarà quindi un campione $((x_{i1}, y_{i1}),...,(x_{im},y_{im}))$ di cardinalità $m_i$. Poi, per ogni $i\in[1,n]$ l'algoritmo viene addestrato su un \textit{validation set} costituito da tutti i fold tranne l'i-esimo, per generare un'ipotetica $h_i$, e la performance di $h_i$ viene testata sull'i-esimo fold. Il valore del parametro $\theta$ è scelto sulla base dell'errore medio di $h_i$, chiamato \textit{cross-validation error}, denotato da $\widehat{R}_{CV}(\theta)$ e definito da
	\[
	\widehat{R}_{CV}(\theta)={1\over n}\sum_{i=1}^n {1\over m_i}\sum_{j=m_i}^n L(h_i(x_{ij}),y_{ij})
	\]
	I fold sono generalmente definiti della stessa taglia, ovvero $m_i=m/n$ per ogni $i\in[1,n]$. La scelta di n è molto importante ai fini dell'utilizzo di questo metodo: con un $n$ grande ogni fold avrà taglia prossima ad $m$ (la linea rossa sulla destra in \ref{fig:graph}), la cardinalità dell'intero dataset, ma i fold saranno piuttosto simili, e quindi il metodo avrà un bias ridotto ed una grande varianza. Viceversa, valori bassi di $n$ portano a training set differenziati, ma la loro taglia è significativamente più bassa di $m$ (la linea rossa sulla sinistra in \ref{fig:graph}) e quindi il metodo tenderà ad avere una varianza minore ma un bias maggiore. Solitamente si scelgono come valori per $n$ 5 o 10. \\

	\begin{figure}[h]
		\begin{minipage}{0.47\textwidth}
			\centering
			\includegraphics[width=\textwidth]{CV1.png}
			\caption{n-fold cross validation}
			\label{fig:crossval}
		\end{minipage}
		\hfill
		\begin{minipage}{0.47\textwidth}
			\centering
			\includegraphics[width=\textwidth]{CV2.png}
			\caption{Grafico dell'errore di predizione di un classificatore in funzione della dimensione del training set}
			\label{fig:graph}
		\end{minipage}
	\end{figure}


	Per la model selection, quindi, la cross validation è utilizzata in questo modo: l'intero dataset viene suddiviso inizialmente in training e test set, dove il training set ha taglia $m$. Questo viene poi utilizzato per computare il cross validation error $\widehat{R}_{CV}(\theta)$ per un certo numero di possibili valori di $\theta$; viene considerato come $\theta_0$ il valore per cui $\widehat{R}_{CV}(\theta)$ è minore, e l'algoritmo viene addestrato con i parametri di $\theta_0$ sull'intero training set di taglia $m$. La sua performance è poi valutata sul test set.
	Il metodo si può applicare allo stesso modo per quanto riguarda la fase di training: si otterranno delle valutazioni parziali (accuratezze o errori), di cui possiamo calcolare la media per avere un'indicazione della bontà dell'apprendimento.
	
	\subsection{Insiemi fuzzy e induzione della funzione di membership}
	La teoria classica degli insiemi, inizialmente formulata da Zadeh~\cite{bib:zadeh}, è basata sul concetto fondamentale di \textit{insieme} di cui un elemento fa parte oppure no, una distinzione netta che permette di identificare un chiaro confine tra ciò che appartiene e non appartiene all'insieme. Molti problemi reali non possono però essere descritti e gestiti dalla teoria classica degli insiemi, in quanto trattano elementi che hanno appartenenza solo parziale ad un dato insieme. La teoria dei \textit{fuzzy set} (o insiemi sfocati), generalizza ed estende in questo senso la teoria classica degli insiemi~\cite{bib:fuzzy}~\cite{bib:fuzzy2}.\\
	Nella teoria classica, possiamo definire la funzione caratteristica di un insieme, ovvero la funzione di appartenenza ad un insieme $A$ come
	\[
	X_A(x)=
	\begin{cases}
	1, & if $ x $ \in $ A$\\
	0, & if $ x $ \notin $ A$
	\end{cases}
	\]
	Ma se un elemento ha membership soltanto parziale ad un insieme dobbiamo generalizzare questa funzione per determinare il grado di membership dell'elemento stesso: un valore maggiore indicherà un grado di membership più alto all'insieme. Se consideriamo ad esempio l'insieme universo $S$ di tutti gli esseri umani, e $S_f$ come
	\[
	S_f=\Set{s \in S | s \text{ is old}}\text{,}
	\]
	$S_f$ è un \textit{sottoinsieme fuzzy} di S, perché la proprietà "vecchio" non è ben definita e non può essere misurata in modo preciso: dobbiamo quindi stabilire una funzione che assegni "il valore di vecchiaia" di un essere umano, ma non esiste un criterio unico o universale per scegliere questa funzione.\\
	Un sottoinsieme fuzzy è quindi definito da un sottoinsieme e da una funzione di membership $\mu$ ad esso associata, che associa ad ogni elemento dell'insieme un valore reale nell'intervallo $[0,1]$ (si vedano alcuni esempi in Figura \ref{fig:membership}).\\

	\begin{figure}[h]
		\centering
		{\includegraphics[width=.60\textwidth]{membership.png}} \quad
		\caption{Forme di funzioni di membership comunemente usate}
		\label{fig:membership}
		
	\end{figure}

	Parallelamente alla definizione di insiemi fuzzy si può effettuare una distinzione tra logica classica e logica fuzzy. La logica classica, infatti, riguarda proposizioni che possono essere vere o false ma che non possono mai assumere contemporaneamente entrambi i valori di verità, che hanno opposto e possono essere combinate tra loro.
	La logica fuzzy, che pone la base del ragionamento approssimato, si differenzia da quella tradizionale in quanto ammette l'utilizzo termini linguistici imprecisi come
	\begin{itemize}
		\item{Predicati fuzzy}: vecchio, giovane, alto, veloce
		\item{Quantificatori fuzzy}: molto, poco, quasi, di solito
		\item{Valori di verità fuzzy}: molto vero, probabilmente falso, sicuramente falso
	\end{itemize}	
	che permettono di trattare fenomeni della realtà difficilmente descrivibili in modo quantitativo, ma su cui la maggior parte del ragionamento umano si basa.
	In particolare si dicono \textit{variabili linguistiche} gli attributi dei sistemi fuzzy che assumono \textit{valori linguistici} espressi in linguaggio naturale. Questi valori hanno un significato e non un preciso valore numerico, e partizionano i possibili valori delle variabili linguistiche in modo soggettivo (ovvero solitamente basato sull'intuizione umana).
	Se ad esempio consideriamo come variabile linguistica la superficie abitabile di un appartamento A, e definiamo i valori linguistici $\{tiny, small, medium, large, huge\}$ e le funzione di membership come in Figura \ref{fig:mem2}:
	
	\begin{figure}[h]
		\centering
		{\includegraphics[width=.80\textwidth]{mem2.png}} \quad
		\caption{Esempio: funzioni di membership in riferimento alla superficie abitabile di un appartamento}
		\label{fig:mem2}
	\end{figure}
	Possiamo notare che ogni $x \in A$ ha $\mu(x) \in [0,1]$ per ogni valore. Se ad esempio consideriamo $x=42.5m^2$, avremo che $\mu_t(x)=\mu_s(x)\mu_h(x)=0$, mentre $\mu_m(x)=\mu_l(x)=0.5$.
	\\
	 
	L'applicazione della logica fuzzy a problemi di apprendimento passa attraverso l'utilizzo dei FIS (Fuzzy Inference Systems), che composti da cinque blocchi funzionali: 
	\begin{itemize}
		\item{Rule Base}: contiene le regole if-then fuzzy definite da esperti
		\item{Database}: definisce le membership function dei fuzzy set usati nelle regole fuzzy
		\item{Inference Engine}: esegue operazioni sulle regole
		\item{Fuzzifier}: converte le quantità crisp in quantità fuzzy
		\item{Defuzzifier}: converte le quantità fuzzy in quantità crisp
	\end{itemize}
	\begin{figure}[h]
		\centering
		{\includegraphics[width=.80\textwidth]{fis.jpg}} \quad
		\caption{Struttura di un FIS}
		\label{fig:fis}
	\end{figure}

	Il FIS quindi, e in particolare il fuzzifier converte l'input da crisp a fuzzy, aggiornando la Knowledge Base formata da Database e Rule base; l'input viene poi passato all'Inference Engine, che determina il match con le regole if-then (e aggiorna le regole stesse sulla base dell'input), ovvero associa input fuzzy ad output fuzzy, che viene poi ritrasformato in output crisp dal defuzzifier.
	\\
	I concetti della teoria dei fuzzy set applicati all'apprendimento automatico hanno portato alla nascita del \textit{fuzzy machine learning}, che ha permesso l'estensione di tecniche di apprendimento non fuzzy a corrispondenti tecniche fuzzy: si può parlare di fuzzy clustering, fuzzy support vector machines, fuzzy k-nearest neighbour e così via. Queste tecniche sono utilizzate principalmente in tre tipi di problemi: quelli di classificazione e data analysis, i problemi di decision-making e il ragionamento approssimato; questi problemi mostrano le tre semantiche attribuibili al grado di membership, ovvero la similarità, la preferenza e la possibilità.
	Per quanto riguarda la prima categoria, che approfondiremo in seguito, il grado di membership di un elemento $u$ $\mu(u)$ indica la prossimità al valore che si ha come prototipo; questa semantica è specialmente utilizzata per problemi di pattern classification, clustering e regressione.
	
	Nel campo dell'apprendimento automatico, quindi, le tecniche di induzione di funzioni di appartenenza producono modelli che trasformano variabili di input in gradi di appartenenza ad un insieme fuzzy. Si possono distinguere a questo proposito tecniche induttive o deduttive: l'uso di metodi deduttivi implica la generazione di funzioni di appartenenza da parte di esperti, ovvero sulla percezione umana. Le tecniche induttive, invece, si basano principalmente sui dati. Si approfondiranno in seguito queste ultime, più affidabili in quanto slegate dalle diverse interpretazioni che esperti possono dare agli stessi attributi o variabili.
	

	\section{Tecniche per induzione della funzione di membership}
	Ottenere la funzione di membership a partire dai dati di training è uno dei problemi fondamentali legati all'applicazione della teoria dei fuzzy set, in cui le funzioni di membership vengono utilizzate per mappare l'imprecisione dell'informazione in input. Non ci sono però regole o linee guida che possano essere usate per scegliere l'appropriata tecnica di generazione, e il problema è reso più complesso dalla mancanza di accordo sulla definizione e interpretazione delle funzioni di membership. Le diverse tecniche di induzione spaziano da tecniche basate sulla percezione, ovvero sul giudizio umano o di esperti a tecniche euristiche, che usano forme di funzioni di membership predefinite, tecniche basate su istogrammi (che utilizzano appunto istogrammi per considerare la distribuzione delle features di input), trasformazione di distribuzioni di probabilità in distribuzioni di possibilità, tecniche basate su fuzzy nearest neighbour o su reti neurali (come approfondito in ~\cite{bib:rita}), su clustering o support vector machines(che approfondiremo meglio in seguito); l'intera rassegna è presentata in \cite{bib:rassegna}.
	
	\subsection{Clustering}
	Gli algoritmi classici di clustering hanno come fine il raggruppamento e la selezione di elementi omogenei in un insieme di dati. Dati in input n oggetti, l'algoritmo restituisce in output un clustering $\mathcal{C}=\{c_1, ..., c_k\}$ degli oggetti, ovvero una partizione dell'insieme degli elementi $V$. Due elementi sono detti omogenei o disomogenei in relazione ad una funzione di similarità o dissimilarità $\sigma: V\times V\rightarrow \mathbb{R}$, detta \textit{metrica}, che assegna un valore ad ogni possibile coppia di punti: un esempio banale può essere costituito da una funzione che assegna il valore $1$ ad elementi omogenei e il valore $-1$ ad elementi disomogenei. Si possono utilizzare svariati tipi di funzioni: un esempio comune è la norma (distanza euclidea, una funzione di dissimilarità), che dati due punti $u$ e $v$ è definita come:
	\[
		\sigma(u, v) = \norma{u - v}\text{.}
	\]
	
	\subsubsection{Breve classificazione}
		Dati $v$ e $\sigma$, posso operare due diversi tipi di clustering: il clustering \textit{partition based}, che utilizza una distanza da un punto rappresentativo del cluster (ad esempio il \textit{centroide}) per determinare l'appartenenza di un elemento ad un gruppo, avendo prefissato il numero di gruppi della partizione risultato, oppure clustering \textit{gerarchico}, in cui viene costruita una gerarchia di partizioni visualizzabile mediante una rappresentazione ad albero (dendrogramma), in cui sono rappresentati i passi di accorpamento/divisione dei gruppi stessi.\\
		Le tecniche di clustering si possono inoltre suddividere sulla base del modo in cui operano in \textit{metodi aggregativi} (o \textit{bottom-up}) e \textit{metodi divisivi} (o \textit{top-down}). La prima classe comprende i metodi che considerano inizialmente tutti gli elementi come cluster a sé, e in cui poi l'algoritmo provvede ad unire i cluster più vicini. L'algoritmo continua questo processo fino ad ottenere un numero prefissato di cluster, oppure fino a che la distanza minima tra i cluster non supera un certo valore, o ancora in relazione ad un determinato criterio statistico prefissato.
		I metodi divisivi, invece, prevedono che all'inizio tutti gli elementi siano in un unico cluster: l'algoritmo, poi, inizia a dividere il cluster in tanti sottoinsiemi di dimensioni inferiori, cercando di ottenere gruppi sempre più omogenei. L'algoritmo procede fino a che non viene soddisfatta una regola di arresto generalmente legata al raggiungimento di un numero prefissato di cluster.\\
		\`E possibile inoltre operare un'ulteriore classificazione delle tecniche di clustering: si distingue il clustering di tipo \textit{esclusivo} o \textit{hard clustering}, in cui ogni elemento può essere assegnato ad uno e ad un solo gruppo (di conseguenza i cluster saranno a due a due disgiunti) e il clustering \textit{non-esclusivo}, noto anche con il nome di \textit{soft clustering} o \textit{fuzzy clustering}.

	\subsubsection{Fuzzy clustering}
		I problemi di clustering possono avere applicazioni in svariati campi, come l'economia, psicologia, medicina, biologia; ne è fatto in particolare un vasto utilizzo nel campo della bioinformatica, in cui il fuzzy clustering è preferito a quello classico, nel campo del marketing, in cui ad esempio gli utenti possono essere suddivisi in cluster fuzzy sulla base di bisogni, preferenze e profili o ancora nell'image analysis, in cui è usato in particolare per la segmentazione al fine di svolgere pattern recognition, object detection, e analisi di immagini mediche.
		Nel fuzzy clustering infatti, in opposizione alle tecniche classiche di clustering come il \textit{k-means}, gli elementi di input possono appartenere a più di una partizione, con un certo valore di membership. La membership non rappresenta però una probabilità: la somma dei valori di membership assegnati ad un elemento in relazione a classi opposte non deve perciò dare 1; la membership sarà più bassa se il punto si colloca sul limite esterno del cluster, e viceversa maggiore se l'elemento è vicino al centro del cluster.
		
		La maggior parte dei metodi di fuzzy clustering esistenti fa riferimento come base al \textit{Fuzzy C-Means}, la variante fuzzy del classico k-means. L'algoritmo \textit{k-means}, proposto nel 1967 da MacQueen, è uno degli algoritmi di apprendimento base utilizzato per risolvere problemi di clustering; lo scopo è di classificare un dato dataset di cardinalità $n$ in un certo numero di cluster $k$, definito a priori.
		Si definiscono inizialmente $k$ \textit{centroidi}, uno per ogni cluster. Questi centroidi devono essere scelti in modo accurato, e preferibilmente inizialmente distanti gli uni dagli altri: la posizione dei centroidi iniziali influinìsce infatti sul risultato del clustering. Successivamente, si assegna ogni punto nel dataset al centroide ad esso più vicino (utilizzo come funzione di similarità la norma); a questo punto si ricalcolano i $k$ nuovi centroidi, ottenuti come baricentro dei punti in un dato cluster. Si ripetono queste due operazioni di riassegnazione dei punti e correzione dei centroidi finchè non si hanno più cambiamenti significativi, ovvero finchè il clustering è stabile. Lo scopo di questo algoritmo è infatti quello di minimizzare una funzione obiettivo $J$, espressa come
		\[
			J = \sum_{j=1}^{k}\sum_{i=1}^{n}\norma{x_i^{(j)}-c_j}^2\text{,}
		\]
		ovvero la somma dei quadrati delle distanze di ogni punto dal centro del cluster a cui appartiene. 
		L'algoritmo k-means termina sempre, ma non trova necessariamente il clustering ottimo (quello che minimizza la funzione obiettivo): il problema infatti è np-hard, e l'algoritmo è molto sensibile alla posizione dei cluster iniziali. Per ridurre questo effetto è necessario ripeter più volte l'esecuzione dell'algoritmo.
		Il Fuzzy C-Means parte quindi da questa base e generalizza l'algoritmo in senso fuzzy: in questo algoritmo, gli oggetti che si collocano sul confine di un dato cluster non sono forzati ad appartenere ad un solo cluster, ma possono invece appartenere a diversi insiemi con una membership parziale compresa tra 0 e 1, garantendo una prestazione migliore specialmente in presenza di rumore nei dati o outliers~\cite{bib:kmvsfcm}. A partire dal FCM, quindi, si sono sviluppate una serie di varianti che trattano diverse forme di funzioni di appartenenza, che pongono un'attenzione particolare al rumore e agli outliers come RSFKM~\cite{bib:rsfkm} e GEPFCM~\cite{bib:gepfcm}, algoritmi che risolvono il problema di stabilire a priori il numero di cluster e la sensibilità di FCM alla posizione dei centroidi iniziali, come in~\cite{bib:afkm} o ancora che utilizzano come funzioni di similarità tecniche diverse dalla distanza euclidea, come in KFCM~\cite{bib:kfcm}.
		\\
		Oltre a questa categoria di algoritmi si distinguono algoritmi di fuzzy support vector clustering, una tecnica ibrida tra clustering e uso di support vector machines (come in~\cite{bib:svc}\cite{bib:msvc}).
		\\
		Una rassegna completa dei vari tipi di algoritmi è disponibile in Tabella \ref{tab:clustering}
	
	
	\subsection{Support Vector Machines}
	Le Support Vector Machines, sviluppate da Vapnik nel 1995, sono una tecnica di apprendimento supervisionato utilizzato soprattutto per problemi di classificazione, regressione e detection di outliers; esse sono utilizzate per un vasto numero di applicazioni, dal riconoscimento facciale al processing di dati biologici per diagnosi mediche.\\
	Le SVM hanno come obiettivo quello di identificare un iperpiano "ottimo" come soluzione del problema di apprendimento, ovvero un iperpiano che distingua diverse classi di elementi dell'insieme dei dati di input, e che massimizzi il \textit{margine}, la massima distanza tra i punti delle classi più vicini all'iperpiano e l'iperpiano stesso. In uno spazio bidimensionale, un iperpiano è quindi una retta che divide il piano in due semizpazi. La formulazione più semplice delle SVM è quella lineare, in cui l'iperpiano giace sullo spazio dei dati di input $x$. Lo spazio d'ipotesi sarà quindi in questo caso un sottoinsieme dell'insieme che contiene tutti gli iperpriani della forma 
	\[
	f(x) = w\cdot x+b\text{.}
	\]
	Se i dati non sono linearmente separabili, però, potrebbe accadere che questo iperpiano non sia identificabile: la soluzione è quella di aggiungere un'ulteriore dimensione ottenuta come combinazione delle precedenti (indotto da un kernel), in modo da ottenere un ulteriore spazio a più dimensioni, detto \textit{spazio delle features}, e identificare nel nuovo spazio un iperpiano ottimo.\\
	
	L'uso delle SVM prevede una fase di tuning dei parametri, che in questo caso sono il kernel, il parametro di regolarizzazione e gamma. Per quanto riguarda il kernel, questo stabilisce il tipo di trasformazione che lo spazio iniziale subisce: si distinguono ad esempio kernel lineari, polinomiali ed esponenziali (questi ultimi due calcolano l'iperpiano separatore in uno spazio a più dimensioni). Il parametro di regolarizzazione, invece, esprime quanto è importante che ogni punto venga classificato in modo corretto: sulla base di questo parametro: per valori grandi, l'algoritmo sceglierà un iperpiano con un margine minore, affinché tutti i punti vengano assegnati alla classe corretta; viceversa per valori bassi del parametro l'iperpiano avrà margine maggiore, ma alcuni punti saranno classificati in modo non corretto, come si può vedere in \ref{fig:svm}
	
	\begin{figure}[h]
		\centering
		\subfloat[\emph{}]
		{\includegraphics[width=.45\textwidth]{svm.png}} \quad
		\subfloat[\emph{}]
		{\includegraphics[width=.45\textwidth]{svm2.png}} \\
		\caption{Sulla destra: valori bassi del parametro di regolarizzazione; sulla sinistra valori più elevati}
		\label{fig:svm}
	\end{figure}
	Il parametro \textit{gamma}, infine, indica quanto lontano dall'iperpiano arriva l'influenza del singolo punto, dove valori bassi del parametro indicano che punti lontani dal possibile iperpiano influenzano la scelta dell'iperpiano stesso, e viceversa.	
	
	\subsection{Fuzzy Support Vector Machines}
	
	\section{Implementazione ed esperimenti}
	\subsection{Algoritmi basati su clustering}
	\subsection{Algoritmi basati su support vector machines}
	\subsection{Risultati}
	\section{Conclusioni}
	\newpage
	\section{Tabelle utili(?)}
		\begin{table}[h!]
			\caption{Rassegna di metodi per fuzzy clustering}
			\begin{center}\begin{tabular}{ |c|c|c|c| } 
					\hline
					Categoria & Nome metodo & Anno di pubblicazione & Articolo\\
					\hline
					\multirow{10}{4em}{estensioni a FCM} & RSFKM & 2016 & \cite{bib:rsfkm}\\ 
														& Agglomerative FCM & 2008 & \cite{bib:afkm}\\
														& FKM con FIS & 2013 & \cite{bib:fkmfis}\\ 
														& GIFP-FCM & 2009 & \cite{bib:gifpfcm}\\
														& BCPFCM, BCPNFCM e BCSP NFCM & 2016 & \cite{bib:bcpfcm}\\
														& REFCMFS & 2019 & \cite{bib:refcmfs}\\ 
														& CSFCM & 2015 & \cite{bib:csfcm}\\
														& ICFFCM & 2019 &\cite{bib:icffcm}\\
														& KFCM & 2003 &\cite{bib:kfcm}\\
														& DOFCM & 2011 & \cite{bib:dofcm}\\
					\hline													
					\multirow{2}{4em}{Support Vector Clustering}	& SVC & 2013 & \cite{bib:svc}\\ 
																	& MSVC & 2016 & \cite{bib:msvc}\\ 
																	&  &  & \\
					\hline
					& Shadowed Set Induction & 2018 & \cite{bib:ssi} \\
					\hline
					\multirow{2}{4em}{Spectral Clustering}	& FKSC & 2018 & \cite{bib:fksc}\\ 
															& SSC-PC & 2016 & \cite{bib:sscpc}\\ 
					\hline
					& PFCM & 1993 & \cite{bib:pfcm}\\
					\hline
			\end{tabular}
		\end{center}
		\label{tab:clustering}	
	\end{table}		

	\begin{table}[h!]
		\caption{Rassegna di metodi per fuzzy support vector machines}
		\begin{center}\begin{tabular}{ |c|c|c| } 
				\hline
				Nome metodo & Anno di pubblicazione & Articolo\\
				\hline
				Agglomerative FCM & 2008 & \cite{bib:afkm}\\
				\hline
				FKM con FIS & 2013 & \cite{bib:fkmfis}\\ 
				\hline
				GIFP-FCM & 2009 & \cite{bib:gifpfcm}\\
				\hline
				BCPFCM, BCPNFCM e BCSP NFCM & 2016 & \cite{bib:bcpfcm}\\
				\hline
				REFCMFS & 2019 & \cite{bib:refcmfs}\\ 
				\hline
				CSFCM & 2015 & \cite{bib:csfcm}\\
				\hline
				ICFFCM & 2019 &\cite{bib:icffcm}\\
				\hline
				KFCM & 2003 &\cite{bib:kfcm}\\
				\hline
				DOFCM & 2011 & \cite{bib:dofcm}\\
				\hline													
			\end{tabular}
		\end{center}
		%\label{tab:svm}	
	\end{table}			
			
		
	\section{Riferimenti bibliografici}


\bibliography{Bibliografia}{}

\end{document}