{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from cvxopt import matrix as cvxopt_matrix\n",
    "from cvxopt import solvers as cvxopt_solvers\n",
    "from sklearn import svm\n",
    "import math \n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "dataset=pd.read_csv(\"iris-setosa.csv\")\n",
    "\n",
    "X = dataset.columns[1:3]\n",
    "X = dataset[X]\n",
    "y = dataset.columns[0]\n",
    "y = dataset[y]\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X=X.astype(float)\n",
    "y=y.astype(float)\n",
    "y=np.where(y==0,-1,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, x2)\n",
    "\n",
    "def polynomial_kernel(x, y, p=3):\n",
    "    return (1 + np.dot(x, y)) ** p\n",
    "\n",
    "def gaussian_kernel(x, y, sigma=90.0):\n",
    "    # print(-linalg.norm(x-y)**2)\n",
    "    x=np.asarray(x)\n",
    "    y=np.asarray(y)\n",
    "    return np.exp((-linalg.norm(x-y)**2) / (2 * (sigma ** 2)))\n",
    "\n",
    "#geometric mean\n",
    "def score(y_predict,y_test):\n",
    "    test_min=0\n",
    "    test_max=0\n",
    "    pred_min=0\n",
    "    pred_max=0\n",
    "    y_test=np.asarray(y_test)\n",
    "    for i in range(0,len(y_test)):\n",
    "        if(y_test[i]==1):\n",
    "            test_min=test_min+1\n",
    "        else:\n",
    "            test_max=test_max+1\n",
    "    print(\"y_test min\",test_min)       \n",
    "    print(\"y_test max\",test_max)\n",
    "    for i in range(0,len(y_predict)):\n",
    "        if(y_predict[i]==1 and y_predict[i]==y_test[i]):\n",
    "            pred_min=pred_min+1\n",
    "        elif(y_predict[i]==-1 and y_predict[i]==y_test[i]):\n",
    "            pred_max=pred_max+1\n",
    "    print(\"y_pred min\",pred_min)       \n",
    "    print(\"y_pred max\",pred_max)\n",
    "    se=pred_min/test_min\n",
    "    sp=pred_max/test_max\n",
    "    print(se,sp)\n",
    "    gm=math.sqrt(se*sp)\n",
    "    print(\"GM\",gm)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxopt import matrix\n",
    "class HYP_SVM(object):\n",
    "\n",
    "    #geometric mean\n",
    "    def score(y_predict,y_test):\n",
    "        test_min=0\n",
    "        test_max=0\n",
    "        pred_min=0\n",
    "        pred_max=0\n",
    "        y_test=np.asarray(y_test)\n",
    "        for i in range(0,len(y_test)):\n",
    "            if(y_test[i]==1):\n",
    "                test_min=test_min+1\n",
    "            else:\n",
    "                test_max=test_max+1\n",
    "        print(\"y_test min\",test_min)       \n",
    "        print(\"y_test max\",test_max)\n",
    "        for i in range(0,len(y_predict)):\n",
    "            if(y_predict[i]==1 and y_predict[i]==y_test[i]):\n",
    "                pred_min=pred_min+1\n",
    "            elif(y_predict[i]==-1 and y_predict[i]==y_test[i]):\n",
    "                pred_max=pred_max+1\n",
    "        print(\"y_pred min\",pred_min)       \n",
    "        print(\"y_pred max\",pred_max)\n",
    "        se=pred_min/test_min\n",
    "        sp=pred_max/test_max\n",
    "        print(se,sp)\n",
    "        gm=math.sqrt(se*sp)\n",
    "        print(\"GM\",gm)    \n",
    "    \n",
    "    def __init__(self, kernel=gaussian_kernel, sigma=None, C=None):\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "        self.sigma = sigma\n",
    "        if self.C is not None: self.C = float(self.C)\n",
    "            \n",
    "    def get_params(self, deep=True):\n",
    "        return {\"C\": self.C, \"sigma\": self.sigma, \"kernel\": self.kernel}        \n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def m_func(self, X_train,X_test, y):\n",
    "        n_samples, n_features = X_train.shape \n",
    "        nt_samples, nt_features= X_test.shape\n",
    "        self.K = np.zeros((n_samples, n_samples))\n",
    "        for i in range(n_samples):\n",
    "            for j in range(n_samples):\n",
    "                self.K[i,j] = gaussian_kernel(X_train[i], X_train[j], self.sigma)\n",
    "               # print(K[i,j])\n",
    "        X_train=np.asarray(X_train)\n",
    "        X_test=np.asarray(X_test)\n",
    "        K1 = np.zeros((n_samples, n_samples))\n",
    "        for i in range(n_samples):\n",
    "            for j in range(n_samples):\n",
    "                K1[i,j] = gaussian_kernel(X_train[i], X_train[j], self.sigma)\n",
    "               # print(K[i,j])\n",
    "        print(K1.shape)\n",
    "        P = cvxopt.matrix(np.outer(y,y) * self.K)\n",
    "        q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
    "        A = cvxopt.matrix(y, (1,n_samples))\n",
    "        A = matrix(A, (1,n_samples), 'd') #changes done\n",
    "        b = cvxopt.matrix(0.0)\n",
    "        #print(P,q,A,b)\n",
    "        if self.C is None:\n",
    "            G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "            h = cvxopt.matrix(np.zeros(n_samples))\n",
    "            \n",
    "        else:\n",
    "            tmp1 = np.diag(np.ones(n_samples) * -1)\n",
    "            tmp2 = np.identity(n_samples)\n",
    "            G = cvxopt.matrix(np.vstack((tmp1, tmp2)))\n",
    "            tmp1 = np.zeros(n_samples)\n",
    "            tmp2 = np.ones(n_samples) * self.C\n",
    "            h = cvxopt.matrix(np.hstack((tmp1, tmp2)))\n",
    "        # solve QP problem\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "        print(solution['status'])\n",
    "        # Lagrange multipliers\n",
    "        a = np.ravel(solution['x'])\n",
    "        a_org = np.ravel(solution['x'])\n",
    "        # Support vectors have non zero lagrange multipliers\n",
    "        sv = a > 1e-5\n",
    "        #print(sv.shape)\n",
    "        ind = np.arange(len(a))[sv]\n",
    "        self.a_org=a\n",
    "        self.a = a[sv]\n",
    "        self.sv = X_train[sv]\n",
    "        self.sv_y = y[sv]\n",
    "        self.sv_yorg=y\n",
    "        self.kernel = gaussian_kernel\n",
    "        X_train=np.asarray(X_train)\n",
    "        b = 0\n",
    "        for n in range(len(self.a)):\n",
    "            b += self.sv_y[n]\n",
    "            b -= np.sum(self.a * self.sv_y * self.K[ind[n],sv])\n",
    "        b /= len(self.a)\n",
    "       # print(self.a_org[1])\n",
    "        #print(self.a_org.shape,self.sv_yorg.shape,K.shape)\n",
    "        w_phi=0\n",
    "        total=0\n",
    "        for n in range(len(self.a_org)):\n",
    "            w_phi = self.a_org[n] * self.sv_yorg[n] * K1[n] \n",
    "        self.d_hyp=np.zeros(n_samples)\n",
    "        for n in range(len(self.a_org)):\n",
    "            self.d_hyp += self.sv_yorg[n]*(w_phi+b)\n",
    "        func=np.zeros((n_samples))\n",
    "        func=np.asarray(func)\n",
    "        typ=1\n",
    "        if(typ==1):\n",
    "            for i in range(n_samples):\n",
    "                func[i]=1-(self.d_hyp[i]/(np.amax(self.d_hyp[i])+0.000001))\n",
    "        beta=0.8\n",
    "        if(typ==2):\n",
    "            for i in range(n_samples):\n",
    "                func[i]=2/(1+beta*self.d_hyp[i])\n",
    "        r_max=103/4074\n",
    "        r_min=1\n",
    "        self.m=func[0:115]*r_min\n",
    "        print(self.m.shape)\n",
    "        self.m=np.append(self.m,func[115:5473]*r_max)\n",
    "        print(self.m.shape)\n",
    "        \n",
    " ##############################################################################\n",
    "\n",
    "    #prendeva come argomento anche x_test, l'ho tolto, ho aggiunto K\n",
    "    def fit(self, X_train, y):\n",
    "        self.kernel = gaussian_kernel\n",
    "        n_samples, n_features = X_train.shape \n",
    "        #nt_samples, nt_features = X_test.shape\n",
    "        # Gram matrix\n",
    "\n",
    "        print(self.K.shape)\n",
    "\n",
    "        P = cvxopt.matrix(np.outer(y,y) * self.K)\n",
    "        q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
    "        A = cvxopt.matrix(y, (1,n_samples))\n",
    "        A = matrix(A, (1,n_samples), 'd') #changes done\n",
    "        b = cvxopt.matrix(0.0)\n",
    "        #print(P,q,A,b)\n",
    "        if self.C is None:\n",
    "            G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "            h = cvxopt.matrix(np.zeros(n_samples))\n",
    "            \n",
    "        else:\n",
    "            tmp1 = np.diag(np.ones(n_samples) * -1)\n",
    "            tmp2 = np.identity(n_samples)\n",
    "            G = cvxopt.matrix(np.vstack((tmp1, tmp2)))\n",
    "            tmp1 = np.zeros(n_samples)\n",
    "            tmp2 = np.ones(n_samples) * self.C\n",
    "            h = cvxopt.matrix(np.hstack((tmp1, tmp2)))\n",
    "        # solve QP problem\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "        print(solution['status'])\n",
    "        # Lagrange multipliers\n",
    "        a = np.ravel(solution['x'])\n",
    "        a_org = np.ravel(solution['x'])\n",
    "        # Support vectors have non zero lagrange multipliers\n",
    "        for i in range(n_samples):\n",
    "            sv=np.logical_or(self.a_org <self.m, self.a_org > 1e-5)\n",
    "        #print(sv.shape)\n",
    "        ind = np.arange(len(a))[sv]\n",
    "        self.a = a[sv]\n",
    "        self.sv = X_train[sv]\n",
    "        self.sv_y = y[sv]\n",
    "        #print(\"%d support vectors out of %d points\" % (len(self.a), n_samples))\n",
    "\n",
    "        # Intercept\n",
    "        self.b = 0\n",
    "        for n in range(len(self.a)):\n",
    "            self.b += self.sv_y[n]\n",
    "            self.b -= np.sum(self.a * self.sv_y * self.K[ind[n],sv])\n",
    "        self.b /= len(self.a)\n",
    "        print(self.b)\n",
    "\n",
    "        # Weight vector\n",
    "        if self.kernel == gaussian_kernel:\n",
    "            self.w = np.zeros(n_features)\n",
    "            for n in range(len(self.a)):\n",
    "                self.w += self.a[n] * self.sv_y[n] * self.sv[n]\n",
    "        else :\n",
    "            self.w = None        \n",
    "        \n",
    "    def project(self, X):\n",
    "        if self.w is None:\n",
    "            return np.dot(X, self.w) + self.b\n",
    "        else:\n",
    "            y_predict = np.zeros(len(X))\n",
    "            X=np.asarray(X)\n",
    "            for i in range(len(X)):\n",
    "                s = 0\n",
    "                for a, sv_y, sv in zip(self.a, self.sv_y, self.sv):\n",
    "                    s += a * sv_y * gaussian_kernel(X[i], sv, self.sigma)\n",
    "                y_predict[i] = s\n",
    "                print(y_predict[i]+self.b)\n",
    "                #print(self.b)\n",
    "            return y_predict + self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.project(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Using C= 0.01 and sigma= 0.09\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.8532e+01 -8.3103e+00  5e+02  2e+01  3e-16\n",
      " 1: -7.2111e+00 -3.0922e+00  4e+01  2e+00  4e-16\n",
      " 2: -8.0984e-01 -2.2334e+00  2e+00  2e-02  1e-15\n",
      " 3: -7.8553e-01 -8.5733e-01  7e-02  2e-04  4e-16\n",
      " 4: -7.9153e-01 -7.9821e-01  7e-03  2e-05  4e-16\n",
      " 5: -7.9264e-01 -7.9355e-01  9e-04  1e-06  3e-16\n",
      " 6: -7.9283e-01 -7.9296e-01  1e-04  6e-08  3e-16\n",
      " 7: -7.9285e-01 -7.9287e-01  1e-05  2e-09  3e-16\n",
      " 8: -7.9286e-01 -7.9286e-01  8e-07  5e-11  3e-16\n",
      " 9: -7.9286e-01 -7.9286e-01  4e-08  7e-13  4e-16\n",
      "Optimal solution found.\n",
      "optimal\n",
      "(115,)\n",
      "(120,)\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.8532e+01 -8.3103e+00  5e+02  2e+01  3e-16\n",
      " 1: -7.2111e+00 -3.0922e+00  4e+01  2e+00  4e-16\n",
      " 2: -8.0984e-01 -2.2334e+00  2e+00  2e-02  1e-15\n",
      " 3: -7.8553e-01 -8.5733e-01  7e-02  2e-04  4e-16\n",
      " 4: -7.9153e-01 -7.9821e-01  7e-03  2e-05  4e-16\n",
      " 5: -7.9264e-01 -7.9355e-01  9e-04  1e-06  3e-16\n",
      " 6: -7.9283e-01 -7.9296e-01  1e-04  6e-08  3e-16\n",
      " 7: -7.9285e-01 -7.9287e-01  1e-05  2e-09  3e-16\n",
      " 8: -7.9286e-01 -7.9286e-01  8e-07  5e-11  3e-16\n",
      " 9: -7.9286e-01 -7.9286e-01  4e-08  7e-13  4e-16\n",
      "Optimal solution found.\n",
      "optimal\n",
      "-0.3003982591035572\n",
      "-0.2829154379908927\n",
      "-0.2889363441660149\n",
      "-0.2869713647820895\n",
      "-0.29398654869103263\n",
      "-0.26220568664633614\n",
      "-0.2586437698829288\n",
      "-0.30039830110738197\n",
      "-0.2647598516307925\n",
      "-0.27227219219471777\n",
      "-0.2743651063799012\n",
      "-0.30545304249969357\n",
      "-0.30854791803884946\n",
      "-0.30785001430009823\n",
      "-0.31078391839820607\n",
      "-0.31079722348070765\n",
      "-0.30943417170575893\n",
      "-0.3107983722412684\n",
      "-0.31079574119725834\n",
      "-0.3107971124570602\n",
      "-0.30791330557913865\n",
      "-0.30817594381076663\n",
      "-0.31032685483576\n",
      "-0.31147875941841147\n",
      "-0.31079858642048186\n",
      "-0.3107986839391097\n",
      "-0.30121038827499436\n",
      "-0.30152378905389465\n",
      "-0.3078467270063407\n",
      "-0.3113034383131673\n",
      "-0.30676716688852085\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "y_test min 10\n",
      "y_test max 20\n",
      "y_pred min 0\n",
      "y_pred max 20\n",
      "0.0 1.0\n",
      "GM 0.0\n",
      "20 out of 30 predictions correct\n",
      "Accuracy 0.6666666666666666\n",
      "Errore quadratico medio:  1.3333333333333333\n",
      "\n",
      "\n",
      " Using C= 0.01 and sigma= 0.9\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.8947e+00 -4.0113e+00  5e+02  2e+01  5e-16\n",
      " 1: -2.6863e+00 -3.1845e+00  3e+01  1e+00  5e-16\n",
      " 2: -9.7308e-01 -2.1782e+00  3e+00  9e-02  1e-15\n",
      " 3: -7.2146e-01 -1.1230e+00  4e-01  2e-16  2e-15\n",
      " 4: -7.3693e-01 -8.0520e-01  7e-02  2e-17  7e-16\n",
      " 5: -7.4645e-01 -7.6372e-01  2e-02  2e-16  4e-16\n",
      " 6: -7.5092e-01 -7.5514e-01  4e-03  1e-16  4e-16\n",
      " 7: -7.5191e-01 -7.5371e-01  2e-03  3e-17  4e-16\n",
      " 8: -7.5234e-01 -7.5315e-01  8e-04  1e-16  4e-16\n",
      " 9: -7.5260e-01 -7.5285e-01  2e-04  2e-16  4e-16\n",
      "10: -7.5271e-01 -7.5272e-01  2e-05  9e-17  4e-16\n",
      "11: -7.5272e-01 -7.5272e-01  2e-07  2e-16  6e-16\n",
      "Optimal solution found.\n",
      "optimal\n",
      "(115,)\n",
      "(120,)\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.8947e+00 -4.0113e+00  5e+02  2e+01  5e-16\n",
      " 1: -2.6863e+00 -3.1845e+00  3e+01  1e+00  5e-16\n",
      " 2: -9.7308e-01 -2.1782e+00  3e+00  9e-02  1e-15\n",
      " 3: -7.2146e-01 -1.1230e+00  4e-01  2e-16  2e-15\n",
      " 4: -7.3693e-01 -8.0520e-01  7e-02  2e-17  7e-16\n",
      " 5: -7.4645e-01 -7.6372e-01  2e-02  2e-16  4e-16\n",
      " 6: -7.5092e-01 -7.5514e-01  4e-03  1e-16  4e-16\n",
      " 7: -7.5191e-01 -7.5371e-01  2e-03  3e-17  4e-16\n",
      " 8: -7.5234e-01 -7.5315e-01  8e-04  1e-16  4e-16\n",
      " 9: -7.5260e-01 -7.5285e-01  2e-04  2e-16  4e-16\n",
      "10: -7.5271e-01 -7.5272e-01  2e-05  9e-17  4e-16\n",
      "11: -7.5272e-01 -7.5272e-01  2e-07  2e-16  6e-16\n",
      "Optimal solution found.\n",
      "optimal\n",
      "-0.2916786708270218\n",
      "-0.09567500940381538\n",
      "-0.1436530040364182\n",
      "-0.1845386696405363\n",
      "-0.2043392663447281\n",
      "-0.1484371127962909\n",
      "-0.13222022039098102\n",
      "-0.24847814958533382\n",
      "-0.10415480644899833\n",
      "-0.15335973604409203\n",
      "-0.09943376723904021\n",
      "-0.3898634857635007\n",
      "-0.28034760831400524\n",
      "-0.44920887203275095\n",
      "-0.39214155099229386\n",
      "-0.43472326340572753\n",
      "-0.4468826797920043\n",
      "-0.38377679872320447\n",
      "-0.3209618000854987\n",
      "-0.41408555881782727\n",
      "-0.4146828283435204\n",
      "-0.34360403031770587\n",
      "-0.4352567807359109\n",
      "-0.3756859709149287\n",
      "-0.40560803481530616\n",
      "-0.4196929465798588\n",
      "-0.37786830553859885\n",
      "-0.4184859777995631\n",
      "-0.42263138833484737\n",
      "-0.44864351851502177\n",
      "-0.3700208167986976\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "y_test min 10\n",
      "y_test max 20\n",
      "y_pred min 0\n",
      "y_pred max 20\n",
      "0.0 1.0\n",
      "GM 0.0\n",
      "20 out of 30 predictions correct\n",
      "Accuracy 0.6666666666666666\n",
      "Errore quadratico medio:  1.3333333333333333\n",
      "\n",
      "\n",
      " Using C= 0.01 and sigma= 90.0\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.3602e+01 -2.6201e+00  6e+02  3e+01  5e-15\n",
      " 1: -1.3245e+00 -2.5224e+00  8e+00  3e-01  4e-15\n",
      " 2: -7.8950e-01 -1.7593e+00  1e+00  5e-17  8e-16\n",
      " 3: -7.9975e-01 -8.1105e-01  1e-02  1e-16  7e-16\n",
      " 4: -7.9998e-01 -8.0014e-01  2e-04  1e-16  6e-16\n",
      " 5: -7.9998e-01 -8.0001e-01  3e-05  5e-17  9e-16\n",
      " 6: -7.9999e-01 -7.9999e-01  5e-06  1e-16  6e-16\n",
      " 7: -7.9999e-01 -7.9999e-01  1e-06  3e-16  5e-16\n",
      " 8: -7.9999e-01 -7.9999e-01  5e-08  4e-16  4e-16\n",
      "Optimal solution found.\n",
      "optimal\n",
      "(115,)\n",
      "(120,)\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.3602e+01 -2.6201e+00  6e+02  3e+01  5e-15\n",
      " 1: -1.3245e+00 -2.5224e+00  8e+00  3e-01  4e-15\n",
      " 2: -7.8950e-01 -1.7593e+00  1e+00  5e-17  8e-16\n",
      " 3: -7.9975e-01 -8.1105e-01  1e-02  1e-16  7e-16\n",
      " 4: -7.9998e-01 -8.0014e-01  2e-04  1e-16  6e-16\n",
      " 5: -7.9998e-01 -8.0001e-01  3e-05  5e-17  9e-16\n",
      " 6: -7.9999e-01 -7.9999e-01  5e-06  1e-16  6e-16\n",
      " 7: -7.9999e-01 -7.9999e-01  1e-06  3e-16  5e-16\n",
      " 8: -7.9999e-01 -7.9999e-01  5e-08  4e-16  4e-16\n",
      "Optimal solution found.\n",
      "optimal\n",
      "-0.2727840749227144\n",
      "-0.27268209844591573\n",
      "-0.2726890591555272\n",
      "-0.2727001864106906\n",
      "-0.27270511717652157\n",
      "-0.27269317090835843\n",
      "-0.27269212789414127\n",
      "-0.27270129193342574\n",
      "-0.27268511277645235\n",
      "-0.2726921854479536\n",
      "-0.2726800707647747\n",
      "-0.27274129708163264\n",
      "-0.2727142771213825\n",
      "-0.27276721977191126\n",
      "-0.27273926778482016\n",
      "-0.2727502287312099\n",
      "-0.2727592175723477\n",
      "-0.2727382818877544\n",
      "-0.2727241923162394\n",
      "-0.2727441989290582\n",
      "-0.2727442549962514\n",
      "-0.2727281935849376\n",
      "-0.27275121510998807\n",
      "-0.2727342236250707\n",
      "-0.27274123993264754\n",
      "-0.2727501733475364\n",
      "-0.27282026308048696\n",
      "-0.27278218072367644\n",
      "-0.27278820932739434\n",
      "-0.27275823119374976\n",
      "-0.2727361412822054\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "y_test min 10\n",
      "y_test max 20\n",
      "y_pred min 0\n",
      "y_pred max 20\n",
      "0.0 1.0\n",
      "GM 0.0\n",
      "20 out of 30 predictions correct\n",
      "Accuracy 0.6666666666666666\n",
      "Errore quadratico medio:  1.3333333333333333\n",
      "\n",
      "\n",
      " Using C= 0.01 and sigma= 900.0\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.3864e+01 -2.5355e+00  6e+02  3e+01  3e-15\n",
      " 1: -1.3258e+00 -2.5227e+00  8e+00  3e-01  3e-15\n",
      " 2: -7.8963e-01 -1.7596e+00  1e+00  5e-16  8e-16\n",
      " 3: -7.9977e-01 -8.1102e-01  1e-02  2e-16  8e-16\n",
      " 4: -8.0000e-01 -8.0011e-01  1e-04  4e-16  5e-16\n",
      " 5: -8.0000e-01 -8.0000e-01  2e-06  2e-16  5e-16\n",
      " 6: -8.0000e-01 -8.0000e-01  3e-07  1e-16  5e-16\n",
      "Optimal solution found.\n",
      "optimal\n",
      "(115,)\n",
      "(120,)\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.3864e+01 -2.5355e+00  6e+02  3e+01  3e-15\n",
      " 1: -1.3258e+00 -2.5227e+00  8e+00  3e-01  3e-15\n",
      " 2: -7.8963e-01 -1.7596e+00  1e+00  5e-16  8e-16\n",
      " 3: -7.9977e-01 -8.1102e-01  1e-02  2e-16  8e-16\n",
      " 4: -8.0000e-01 -8.0011e-01  1e-04  4e-16  5e-16\n",
      " 5: -8.0000e-01 -8.0000e-01  2e-06  2e-16  5e-16\n",
      " 6: -8.0000e-01 -8.0000e-01  3e-07  1e-16  5e-16\n",
      "Optimal solution found.\n",
      "optimal\n",
      "-0.33333321114720504\n",
      "-0.3333326778001031\n",
      "-0.3333328246192506\n",
      "-0.3333328503567152\n",
      "-0.33333299793132015\n",
      "-0.33333276332293293\n",
      "-0.33333279359328644\n",
      "-0.33333276030144326\n",
      "-0.3333327065595206\n",
      "-0.33333273380806455\n",
      "-0.3333326785556185\n",
      "-0.33333334304465023\n",
      "-0.3333329646391191\n",
      "-0.3333338115059787\n",
      "-0.3333333438001639\n",
      "-0.33333354889373873\n",
      "-0.3333336949573564\n",
      "-0.33333331428522367\n",
      "-0.33333320000294747\n",
      "-0.33333349137487084\n",
      "-0.3333334315894843\n",
      "-0.33333325827733756\n",
      "-0.3333335784086699\n",
      "-0.33333331579623027\n",
      "-0.3333334028300522\n",
      "-0.3333336086790618\n",
      "-0.33333453879938635\n",
      "-0.3333340748731187\n",
      "-0.3333341323919108\n",
      "-0.3333336654424422\n",
      "-0.3333334346114603\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "y_test min 10\n",
      "y_test max 20\n",
      "y_pred min 0\n",
      "y_pred max 20\n",
      "0.0 1.0\n",
      "GM 0.0\n",
      "20 out of 30 predictions correct\n",
      "Accuracy 0.6666666666666666\n",
      "Errore quadratico medio:  1.3333333333333333\n",
      "\n",
      "\n",
      " Using C= 0.01 and sigma= 9000.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.3867e+01 -2.5347e+00  6e+02  3e+01  3e-15\n",
      " 1: -1.3258e+00 -2.5227e+00  8e+00  3e-01  4e-15\n",
      " 2: -7.8964e-01 -1.7596e+00  1e+00  4e-17  8e-16\n",
      " 3: -7.9977e-01 -8.1102e-01  1e-02  7e-17  7e-16\n",
      " 4: -8.0000e-01 -8.0011e-01  1e-04  5e-17  6e-16\n",
      " 5: -8.0000e-01 -8.0000e-01  1e-06  3e-16  5e-16\n",
      " 6: -8.0000e-01 -8.0000e-01  2e-08  2e-16  7e-16\n",
      "Optimal solution found.\n",
      "optimal\n",
      "(115,)\n",
      "(120,)\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.3867e+01 -2.5347e+00  6e+02  3e+01  3e-15\n",
      " 1: -1.3258e+00 -2.5227e+00  8e+00  3e-01  4e-15\n",
      " 2: -7.8964e-01 -1.7596e+00  1e+00  4e-17  8e-16\n",
      " 3: -7.9977e-01 -8.1102e-01  1e-02  7e-17  7e-16\n",
      " 4: -8.0000e-01 -8.0011e-01  1e-04  5e-17  6e-16\n",
      " 5: -8.0000e-01 -8.0000e-01  1e-06  3e-16  5e-16\n",
      " 6: -8.0000e-01 -8.0000e-01  2e-08  2e-16  7e-16\n",
      "Optimal solution found.\n",
      "optimal\n",
      "-0.3333333323987813\n",
      "-0.33333332634835877\n",
      "-0.3333333280744276\n",
      "-0.33333332800890897\n",
      "-0.33333332982054703\n",
      "-0.3333333270930646\n",
      "-0.3333333275409613\n",
      "-0.3333333267507874\n",
      "-0.33333332662511717\n",
      "-0.33333332673073696\n",
      "-0.33333332643392816\n",
      "-0.33333333314164737\n",
      "-0.33333332903037316\n",
      "-0.333333338511043\n",
      "-0.3333333332272166\n",
      "-0.3333333355923715\n",
      "-0.3333333372328713\n",
      "-0.33333333286488903\n",
      "-0.3333333318434248\n",
      "-0.33333333503885487\n",
      "-0.33333333422863015\n",
      "-0.33333333248251096\n",
      "-0.3333333359546992\n",
      "-0.33333333303602747\n",
      "-0.33333333395187187\n",
      "-0.3333333364025958\n",
      "-0.3333333463712638\n",
      "-0.33333334151528354\n",
      "-0.3333333420688003\n",
      "-0.3333333368705438\n",
      "-0.3333333345709074\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "y_test min 10\n",
      "y_test max 20\n",
      "y_pred min 0\n",
      "y_pred max 20\n",
      "0.0 1.0\n",
      "GM 0.0\n",
      "20 out of 30 predictions correct\n",
      "Accuracy 0.6666666666666666\n",
      "Errore quadratico medio:  1.3333333333333333\n",
      "\n",
      "\n",
      " Using C= 0.01 and sigma= 90000.0\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.3867e+01 -2.5347e+00  6e+02  3e+01  4e-15\n",
      " 1: -1.3258e+00 -2.5227e+00  8e+00  3e-01  4e-15\n",
      " 2: -7.8964e-01 -1.7596e+00  1e+00  4e-16  8e-16\n",
      " 3: -7.9977e-01 -8.1102e-01  1e-02  7e-17  7e-16\n",
      " 4: -8.0000e-01 -8.0011e-01  1e-04  2e-17  6e-16\n",
      " 5: -8.0000e-01 -8.0000e-01  1e-06  1e-16  4e-16\n",
      " 6: -8.0000e-01 -8.0000e-01  1e-08  6e-16  7e-16\n",
      "Optimal solution found.\n",
      "optimal\n",
      "(115,)\n",
      "(120,)\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.3867e+01 -2.5347e+00  6e+02  3e+01  4e-15\n",
      " 1: -1.3258e+00 -2.5227e+00  8e+00  3e-01  4e-15\n",
      " 2: -7.8964e-01 -1.7596e+00  1e+00  4e-16  8e-16\n",
      " 3: -7.9977e-01 -8.1102e-01  1e-02  7e-17  7e-16\n",
      " 4: -8.0000e-01 -8.0011e-01  1e-04  2e-17  6e-16\n",
      " 5: -8.0000e-01 -8.0000e-01  1e-06  1e-16  4e-16\n",
      " 6: -8.0000e-01 -8.0000e-01  1e-08  6e-16  7e-16\n",
      "Optimal solution found.\n",
      "optimal\n",
      "-0.33333333332403753\n",
      "-0.3333333332634061\n",
      "-0.33333333328071413\n",
      "-0.33333333327999864\n",
      "-0.3333333332981769\n",
      "-0.3333333332708322\n",
      "-0.3333333332753379\n",
      "-0.3333333332673512\n",
      "-0.3333333332661713\n",
      "-0.33333333326719644\n",
      "-0.3333333332642763\n",
      "-0.33333333333136245\n",
      "-0.3333333332901903\n",
      "-0.3333333333851821\n",
      "-0.3333333333322326\n",
      "-0.33333333335594206\n",
      "-0.33333333337237997\n",
      "-0.33333333332859694\n",
      "-0.3333333333184054\n",
      "-0.333333333350411\n",
      "-0.33333333334226956\n",
      "-0.33333333332480647\n",
      "-0.33333333335957743\n",
      "-0.3333333333303374\n",
      "-0.33333333333950393\n",
      "-0.3333333333640836\n",
      "-0.3333333334638908\n",
      "-0.3333333334152927\n",
      "-0.3333333334208236\n",
      "-0.3333333333687442\n",
      "-0.3333333333457504\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "y_test min 10\n",
      "y_test max 20\n",
      "y_pred min 0\n",
      "y_pred max 20\n",
      "0.0 1.0\n",
      "GM 0.0\n",
      "20 out of 30 predictions correct\n",
      "Accuracy 0.6666666666666666\n",
      "Errore quadratico medio:  1.3333333333333333\n",
      "\n",
      "\n",
      " Using C= 0.1 and sigma= 0.09\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.9568e+01 -2.6814e+01  5e+02  2e+01  3e-16\n",
      " 1: -1.0705e+01 -2.2072e+01  4e+01  1e+00  4e-16\n",
      " 2: -7.0618e+00 -1.2581e+01  6e+00  2e-15  1e-15\n",
      " 3: -7.2189e+00 -7.6321e+00  4e-01  2e-15  4e-16\n",
      " 4: -7.2739e+00 -7.3367e+00  6e-02  2e-15  3e-16\n",
      " 5: -7.2839e+00 -7.2926e+00  9e-03  4e-16  4e-16\n",
      " 6: -7.2856e+00 -7.2863e+00  7e-04  9e-16  3e-16\n",
      " 7: -7.2858e+00 -7.2858e+00  4e-05  6e-16  3e-16\n",
      " 8: -7.2858e+00 -7.2858e+00  1e-06  2e-15  3e-16\n",
      "Optimal solution found.\n",
      "optimal\n",
      "(115,)\n",
      "(120,)\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.9568e+01 -2.6814e+01  5e+02  2e+01  3e-16\n",
      " 1: -1.0705e+01 -2.2072e+01  4e+01  1e+00  4e-16\n",
      " 2: -7.0618e+00 -1.2581e+01  6e+00  2e-15  1e-15\n",
      " 3: -7.2189e+00 -7.6321e+00  4e-01  2e-15  4e-16\n",
      " 4: -7.2739e+00 -7.3367e+00  6e-02  2e-15  3e-16\n",
      " 5: -7.2839e+00 -7.2926e+00  9e-03  4e-16  4e-16\n",
      " 6: -7.2856e+00 -7.2863e+00  7e-04  9e-16  3e-16\n",
      " 7: -7.2858e+00 -7.2858e+00  4e-05  6e-16  3e-16\n",
      " 8: -7.2858e+00 -7.2858e+00  1e-06  2e-15  3e-16\n",
      "Optimal solution found.\n",
      "optimal\n",
      "-0.32967811956884086\n",
      "-0.1548499088462509\n",
      "-0.21505897041183897\n",
      "-0.1954092496164238\n",
      "-0.2655610155920976\n",
      "0.052247604081592625\n",
      "0.08786677165697065\n",
      "-0.3296785395317128\n",
      "0.026705954311896207\n",
      "-0.04841745115234697\n",
      "-0.06934659288325473\n",
      "-0.38022034974247754\n",
      "-0.4111610759856183\n",
      "-0.40418502558977565\n",
      "-0.43350971756107437\n",
      "-0.4336610309685888\n",
      "-0.42002361815316336\n",
      "-0.4336602485876464\n",
      "-0.4336610509866199\n",
      "-0.43366062752136364\n",
      "-0.4048142335169389\n",
      "-0.40745603661739227\n",
      "-0.42895724398767665\n",
      "-0.4404786797236903\n",
      "-0.4336609991964943\n",
      "-0.4336612059473302\n",
      "-0.3377986144144711\n",
      "-0.34093138613834484\n",
      "-0.4041501840647373\n",
      "-0.43871414809480164\n",
      "-0.3933726460070498\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "y_test min 10\n",
      "y_test max 20\n",
      "y_pred min 3\n",
      "y_pred max 20\n",
      "0.3 1.0\n",
      "GM 0.5477225575051661\n",
      "23 out of 30 predictions correct\n",
      "Accuracy 0.7666666666666667\n",
      "Errore quadratico medio:  0.9333333333333333\n",
      "\n",
      "\n",
      " Using C= 0.1 and sigma= 0.9\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.2012e+00 -1.9674e+01  5e+02  2e+01  6e-16\n",
      " 1: -3.3373e+00 -1.8080e+01  2e+01  3e-01  7e-16\n",
      " 2: -3.3017e+00 -4.9680e+00  2e+00  5e-03  4e-16\n",
      " 3: -3.6500e+00 -4.2147e+00  6e-01  1e-03  4e-16\n",
      " 4: -3.8226e+00 -3.9368e+00  1e-01  1e-04  4e-16\n",
      " 5: -3.8574e+00 -3.8926e+00  4e-02  3e-05  4e-16\n",
      " 6: -3.8713e+00 -3.8755e+00  4e-03  7e-07  4e-16\n",
      " 7: -3.8731e+00 -3.8733e+00  2e-04  3e-08  4e-16\n",
      " 8: -3.8732e+00 -3.8732e+00  7e-06  9e-10  4e-16\n",
      " 9: -3.8732e+00 -3.8732e+00  7e-08  1e-11  4e-16\n",
      "Optimal solution found.\n",
      "optimal\n",
      "(115,)\n",
      "(120,)\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.2012e+00 -1.9674e+01  5e+02  2e+01  6e-16\n",
      " 1: -3.3373e+00 -1.8080e+01  2e+01  3e-01  7e-16\n",
      " 2: -3.3017e+00 -4.9680e+00  2e+00  5e-03  4e-16\n",
      " 3: -3.6500e+00 -4.2147e+00  6e-01  1e-03  4e-16\n",
      " 4: -3.8226e+00 -3.9368e+00  1e-01  1e-04  4e-16\n",
      " 5: -3.8574e+00 -3.8926e+00  4e-02  3e-05  4e-16\n",
      " 6: -3.8713e+00 -3.8755e+00  4e-03  7e-07  4e-16\n",
      " 7: -3.8731e+00 -3.8733e+00  2e-04  3e-08  4e-16\n",
      " 8: -3.8732e+00 -3.8732e+00  7e-06  9e-10  4e-16\n",
      " 9: -3.8732e+00 -3.8732e+00  7e-08  1e-11  4e-16\n",
      "Optimal solution found.\n",
      "optimal\n",
      "-0.20927830541385287\n",
      "1.1595893444591654\n",
      "0.8736265718419255\n",
      "0.5310598652980866\n",
      "0.45260615831511075\n",
      "0.779032223097576\n",
      "0.9129940554986263\n",
      "0.059301492542074646\n",
      "1.0998379405158156\n",
      "0.7382886197744054\n",
      "1.1464243475786464\n",
      "-0.9028471644382378\n",
      "-0.16528491320651367\n",
      "-1.2230943797573046\n",
      "-0.8970855806865264\n",
      "-1.1338201227665274\n",
      "-1.205844417110797\n",
      "-0.8544287824592854\n",
      "-0.37102089016638573\n",
      "-0.984750368773936\n",
      "-1.028402033549884\n",
      "-0.5202262952751397\n",
      "-1.1299150175618715\n",
      "-0.7543674439153228\n",
      "-0.9593777263138179\n",
      "-1.0201621567132297\n",
      "-0.7876043530796524\n",
      "-1.0653386342874007\n",
      "-1.0794138839195584\n",
      "-1.2210449701150405\n",
      "-0.6737520552421137\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "y_test min 10\n",
      "y_test max 20\n",
      "y_pred min 10\n",
      "y_pred max 20\n",
      "1.0 1.0\n",
      "GM 1.0\n",
      "30 out of 30 predictions correct\n",
      "Accuracy 1.0\n",
      "Errore quadratico medio:  0.0\n",
      "\n",
      "\n",
      " Using C= 0.1 and sigma= 90.0\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.8370e+01 -2.5539e+01  6e+02  2e+01  4e-15\n",
      " 1: -8.3868e+00 -2.4296e+01  2e+01  2e-01  4e-15\n",
      " 2: -7.9438e+00 -8.8020e+00  9e-01  9e-16  1e-15\n",
      " 3: -7.9972e+00 -8.0102e+00  1e-02  2e-15  1e-15\n",
      " 4: -7.9982e+00 -8.0001e+00  2e-03  2e-15  9e-16\n",
      " 5: -7.9988e+00 -7.9991e+00  4e-04  1e-15  9e-16\n",
      " 6: -7.9989e+00 -7.9990e+00  1e-04  2e-16  9e-16\n",
      " 7: -7.9990e+00 -7.9990e+00  3e-05  2e-16  1e-15\n",
      " 8: -7.9990e+00 -7.9990e+00  1e-06  1e-15  2e-15\n",
      "Optimal solution found.\n",
      "optimal\n",
      "(115,)\n",
      "(120,)\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.8370e+01 -2.5539e+01  6e+02  2e+01  4e-15\n",
      " 1: -8.3868e+00 -2.4296e+01  2e+01  2e-01  4e-15\n",
      " 2: -7.9438e+00 -8.8020e+00  9e-01  9e-16  1e-15\n",
      " 3: -7.9972e+00 -8.0102e+00  1e-02  2e-15  1e-15\n",
      " 4: -7.9982e+00 -8.0001e+00  2e-03  2e-15  9e-16\n",
      " 5: -7.9988e+00 -7.9991e+00  4e-04  1e-15  9e-16\n",
      " 6: -7.9989e+00 -7.9990e+00  1e-04  2e-16  9e-16\n",
      " 7: -7.9990e+00 -7.9990e+00  3e-05  2e-16  1e-15\n",
      " 8: -7.9990e+00 -7.9990e+00  1e-06  1e-15  2e-15\n",
      "Optimal solution found.\n",
      "optimal\n",
      "-0.3218599612367171\n",
      "-0.3215427330326175\n",
      "-0.32161157430571435\n",
      "-0.321724170177177\n",
      "-0.321772419022614\n",
      "-0.32165404106872286\n",
      "-0.3216430992760954\n",
      "-0.321736410829173\n",
      "-0.321572971420707\n",
      "-0.3216443930011854\n",
      "-0.32152214591868294\n",
      "-0.3221352914835411\n",
      "-0.3218657201878529\n",
      "-0.32239260880749476\n",
      "-0.32211470641172973\n",
      "-0.3222234315637192\n",
      "-0.3223128470652756\n",
      "-0.3221050548680515\n",
      "-0.32196351096575404\n",
      "-0.32216295462874883\n",
      "-0.3221642457359811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.32200340089645224\n",
      "-0.3222330792323991\n",
      "-0.3220638802068202\n",
      "-0.3221340078132655\n",
      "-0.32222213254941284\n",
      "-0.3229218132333312\n",
      "-0.32254114457626765\n",
      "-0.32260161297862056\n",
      "-0.3223032011317773\n",
      "-0.32208188284616085\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "y_test min 10\n",
      "y_test max 20\n",
      "y_pred min 0\n",
      "y_pred max 20\n",
      "0.0 1.0\n",
      "GM 0.0\n",
      "20 out of 30 predictions correct\n",
      "Accuracy 0.6666666666666666\n",
      "Errore quadratico medio:  1.3333333333333333\n",
      "\n",
      "\n",
      " Using C= 0.1 and sigma= 900.0\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.8664e+01 -2.5467e+01  6e+02  2e+01  4e-15\n",
      " 1: -8.3920e+00 -2.4302e+01  2e+01  2e-01  4e-15\n",
      " 2: -7.9459e+00 -8.8054e+00  9e-01  9e-16  1e-15\n",
      " 3: -7.9994e+00 -8.0082e+00  9e-03  1e-15  1e-15\n",
      " 4: -8.0000e+00 -8.0001e+00  1e-04  6e-16  1e-15\n",
      " 5: -8.0000e+00 -8.0000e+00  2e-05  3e-15  1e-15\n",
      " 6: -8.0000e+00 -8.0000e+00  4e-06  3e-15  2e-15\n",
      "Optimal solution found.\n",
      "optimal\n",
      "(115,)\n",
      "(120,)\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.8664e+01 -2.5467e+01  6e+02  2e+01  4e-15\n",
      " 1: -8.3920e+00 -2.4302e+01  2e+01  2e-01  4e-15\n",
      " 2: -7.9459e+00 -8.8054e+00  9e-01  9e-16  1e-15\n",
      " 3: -7.9994e+00 -8.0082e+00  9e-03  1e-15  1e-15\n",
      " 4: -8.0000e+00 -8.0001e+00  1e-04  6e-16  1e-15\n",
      " 5: -8.0000e+00 -8.0000e+00  2e-05  3e-15  1e-15\n",
      " 6: -8.0000e+00 -8.0000e+00  4e-06  3e-15  2e-15\n",
      "Optimal solution found.\n",
      "optimal\n",
      "-0.33333157135592567\n",
      "-0.3333278134900738\n",
      "-0.3333287345517699\n",
      "-0.3333296137927446\n",
      "-0.3333303900564779\n",
      "-0.33332885843911636\n",
      "-0.3333288688938775\n",
      "-0.3333294376319834\n",
      "-0.33332811354038483\n",
      "-0.3333287031866433\n",
      "-0.33332766869264724\n",
      "-0.3333339906619786\n",
      "-0.3333309587927952\n",
      "-0.3333371986925352\n",
      "-0.3333338458647073\n",
      "-0.3333352222294387\n",
      "-0.3333362880876134\n",
      "-0.3333336906117713\n",
      "-0.33333234561252945\n",
      "-0.3333346221287094\n",
      "-0.33333445642079296\n",
      "-0.3333328009158666\n",
      "-0.3333353774820673\n",
      "-0.33333340101683817\n",
      "-0.33333415637047537\n",
      "-0.3333353879366012\n",
      "-0.33334310714961185\n",
      "-0.333339030352534\n",
      "-0.3333396304524342\n",
      "-0.3333361328351555\n",
      "-0.33333387722983576\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "y_test min 10\n",
      "y_test max 20\n",
      "y_pred min 0\n",
      "y_pred max 20\n",
      "0.0 1.0\n",
      "GM 0.0\n",
      "20 out of 30 predictions correct\n",
      "Accuracy 0.6666666666666666\n",
      "Errore quadratico medio:  1.3333333333333333\n",
      "\n",
      "\n",
      " Using C= 0.1 and sigma= 9000.0\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.8667e+01 -2.5467e+01  6e+02  2e+01  4e-15\n",
      " 1: -8.3920e+00 -2.4302e+01  2e+01  2e-01  4e-15\n",
      " 2: -7.9460e+00 -8.8054e+00  9e-01  2e-15  1e-15\n",
      " 3: -7.9995e+00 -8.0082e+00  9e-03  1e-15  1e-15\n",
      " 4: -8.0000e+00 -8.0001e+00  9e-05  1e-15  1e-15\n",
      " 5: -8.0000e+00 -8.0000e+00  1e-06  5e-16  1e-15\n",
      "Optimal solution found.\n",
      "optimal\n",
      "(115,)\n",
      "(120,)\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.8667e+01 -2.5467e+01  6e+02  2e+01  4e-15\n",
      " 1: -8.3920e+00 -2.4302e+01  2e+01  2e-01  4e-15\n",
      " 2: -7.9460e+00 -8.8054e+00  9e-01  2e-15  1e-15\n",
      " 3: -7.9995e+00 -8.0082e+00  9e-03  1e-15  1e-15\n",
      " 4: -8.0000e+00 -8.0001e+00  9e-05  1e-15  1e-15\n",
      " 5: -8.0000e+00 -8.0000e+00  1e-06  5e-16  1e-15\n",
      "Optimal solution found.\n",
      "optimal\n",
      "-0.33333332397339405\n",
      "-0.33333326350617204\n",
      "-0.3333332807530258\n",
      "-0.3333332801153961\n",
      "-0.33333329821371016\n",
      "-0.33333327095932447\n",
      "-0.3333332754304476\n",
      "-0.33333326755349496\n",
      "-0.3333332662743746\n",
      "-0.3333332673396646\n",
      "-0.3333332643576311\n",
      "-0.333333331432162\n",
      "-0.33333329033675635\n",
      "-0.3333333850894692\n",
      "-0.33333333228362044\n",
      "-0.3333333559183433\n",
      "-0.33333337231373517\n",
      "-0.33333332866395854\n",
      "-0.3333333184425985\n",
      "-0.3333333503819311\n",
      "-0.3333333422911487\n",
      "-0.3333333248304645\n",
      "-0.3333333595380034\n",
      "-0.3333333303668732\n",
      "-0.3333333395229452\n",
      "-0.333333364009123\n",
      "-0.33333346366061156\n",
      "-0.3333334151120585\n",
      "-0.3333334206484685\n",
      "-0.3333333686940743\n",
      "-0.3333333456969811\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "y_test min 10\n",
      "y_test max 20\n",
      "y_pred min 0\n",
      "y_pred max 20\n",
      "0.0 1.0\n",
      "GM 0.0\n",
      "20 out of 30 predictions correct\n",
      "Accuracy 0.6666666666666666\n",
      "Errore quadratico medio:  1.3333333333333333\n",
      "\n",
      "\n",
      " Using C= 0.1 and sigma= 90000.0\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.8667e+01 -2.5467e+01  6e+02  2e+01  3e-15\n",
      " 1: -8.3920e+00 -2.4302e+01  2e+01  2e-01  3e-15\n",
      " 2: -7.9460e+00 -8.8054e+00  9e-01  2e-15  1e-15\n",
      " 3: -7.9995e+00 -8.0082e+00  9e-03  9e-16  1e-15\n",
      " 4: -8.0000e+00 -8.0001e+00  9e-05  2e-15  1e-15\n",
      " 5: -8.0000e+00 -8.0000e+00  9e-07  5e-15  1e-15\n",
      "Optimal solution found.\n",
      "optimal\n",
      "(115,)\n",
      "(120,)\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.8667e+01 -2.5467e+01  6e+02  2e+01  3e-15\n",
      " 1: -8.3920e+00 -2.4302e+01  2e+01  2e-01  3e-15\n",
      " 2: -7.9460e+00 -8.8054e+00  9e-01  2e-15  1e-15\n",
      " 3: -7.9995e+00 -8.0082e+00  9e-03  9e-16  1e-15\n",
      " 4: -8.0000e+00 -8.0001e+00  9e-05  2e-15  1e-15\n",
      " 5: -8.0000e+00 -8.0000e+00  9e-07  5e-15  1e-15\n",
      "Optimal solution found.\n",
      "optimal\n",
      "-0.33333333324037384\n",
      "-0.3333333326340607\n",
      "-0.3333333328071393\n",
      "-0.33333333279998856\n",
      "-0.33333333298176965\n",
      "-0.33333333270832244\n",
      "-0.3333333327533785\n",
      "-0.33333333267351467\n",
      "-0.3333333326617132\n",
      "-0.3333333326719658\n",
      "-0.3333333326427603\n",
      "-0.3333333333136245\n",
      "-0.33333333290190237\n",
      "-0.3333333338518174\n",
      "-0.33333333332232506\n",
      "-0.33333333355941797\n",
      "-0.33333333372379614\n",
      "-0.333333333285969\n",
      "-0.3333333331840519\n",
      "-0.3333333335041081\n",
      "-0.333333333422691\n",
      "-0.33333333324806425\n",
      "-0.33333333359577444\n",
      "-0.33333333330337306\n",
      "-0.3333333333950381\n",
      "-0.333333333640831\n",
      "-0.33333333463890225\n",
      "-0.33333333415291927\n",
      "-0.333333334208228\n",
      "-0.33333333368744\n",
      "-0.33333333345749994\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "y_test min 10\n",
      "y_test max 20\n",
      "y_pred min 0\n",
      "y_pred max 20\n",
      "0.0 1.0\n",
      "GM 0.0\n",
      "20 out of 30 predictions correct\n",
      "Accuracy 0.6666666666666666\n",
      "Errore quadratico medio:  1.3333333333333333\n",
      "\n",
      "\n",
      " Using C= 10.0 and sigma= 0.09\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.8144e+02 -3.5922e+03  4e+03  1e-14  3e-15\n",
      " 1:  9.1744e+01 -4.1801e+02  5e+02  5e-14  3e-15\n",
      " 2: -1.6621e+01 -6.9863e+01  5e+01  1e-14  1e-15\n",
      " 3: -2.6026e+01 -3.0720e+01  5e+00  3e-14  3e-16\n",
      " 4: -2.6368e+01 -2.6855e+01  5e-01  2e-14  2e-16\n",
      " 5: -2.6412e+01 -2.6451e+01  4e-02  4e-15  2e-16\n",
      " 6: -2.6417e+01 -2.6419e+01  2e-03  2e-15  2e-16\n",
      " 7: -2.6418e+01 -2.6418e+01  8e-05  3e-14  2e-16\n",
      " 8: -2.6418e+01 -2.6418e+01  1e-06  2e-14  2e-16\n",
      "Optimal solution found.\n",
      "optimal\n",
      "(115,)\n",
      "(120,)\n",
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.8144e+02 -3.5922e+03  4e+03  1e-14  3e-15\n",
      " 1:  9.1744e+01 -4.1801e+02  5e+02  5e-14  3e-15\n",
      " 2: -1.6621e+01 -6.9863e+01  5e+01  1e-14  1e-15\n",
      " 3: -2.6026e+01 -3.0720e+01  5e+00  3e-14  3e-16\n",
      " 4: -2.6368e+01 -2.6855e+01  5e-01  2e-14  2e-16\n",
      " 5: -2.6412e+01 -2.6451e+01  4e-02  4e-15  2e-16\n",
      " 6: -2.6417e+01 -2.6419e+01  2e-03  2e-15  2e-16\n",
      " 7: -2.6418e+01 -2.6418e+01  8e-05  3e-14  2e-16\n",
      " 8: -2.6418e+01 -2.6418e+01  1e-06  2e-14  2e-16\n",
      "Optimal solution found.\n",
      "optimal\n",
      "-0.31493867128482844\n",
      "0.5108775259925687\n",
      "1.000389846993964\n",
      "0.28245224952549364\n",
      "0.09054121090540684\n",
      "1.0003898536205167\n",
      "1.0763190858098084\n",
      "-0.31494143655072826\n",
      "1.0003898469153047\n",
      "1.0003898473418378\n",
      "1.0003898477482664\n",
      "-0.6477646481609234\n",
      "-0.8514409357163837\n",
      "-0.8055392395608847\n",
      "-0.9985754809132913\n",
      "-0.9996091343614363\n",
      "-0.9098391548595095\n",
      "-0.9996101536987044\n",
      "-0.9996061826011939\n",
      "-0.9996090936409348\n",
      "-0.8096761765992699\n",
      "-0.8270812801679772\n",
      "-0.9686304337583239\n",
      "-1.0445140243946645\n",
      "-0.9996101030618223\n",
      "-0.9996101636569082\n",
      "-0.36840899443273467\n",
      "-0.38903718713524676\n",
      "-0.805301279504304\n",
      "-1.0329090485579484\n",
      "-0.7345064100539546\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "y_test min 10\n",
      "y_test max 20\n",
      "y_pred min 9\n",
      "y_pred max 20\n",
      "0.9 1.0\n",
      "GM 0.9486832980505138\n",
      "29 out of 30 predictions correct\n",
      "Accuracy 0.9666666666666667\n",
      "Errore quadratico medio:  0.13333333333333333\n",
      "\n",
      "\n",
      " Using C= 10.0 and sigma= 0.9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c797149c12d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Errore quadratico medio: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mhyp_svm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-c797149c12d4>\u001b[0m in \u001b[0;36mhyp_svm\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;31m#print(len(X_train), len(X_test), len(y_train))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-19e6fa742ee3>\u001b[0m in \u001b[0;36mm_func\u001b[0;34m(self, X_train, X_test, y)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                \u001b[0;31m# print(K[i,j])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-5c98a6f8ce82>\u001b[0m in \u001b[0;36mgaussian_kernel\u001b[0;34m(x, y, sigma)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#geometric mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import pylab as pl           \n",
    "    def hyp_svm():\n",
    "        C_vals = [1e-2, 1e-1, 1e+1, 1e+2, 1e+3, 1e+4]\n",
    "        sigma = [9e-2, 9e-1, 9e+1, 9e+2, 9e+3, 9e+4]\n",
    "        combs = list(itertools.product(C_vals, sigma))\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "        skf2 = StratifiedKFold(n_splits=len(combs), shuffle=True, random_state=1)\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            i=0\n",
    "            for train_index, test_index in skf2.split(X_train, y_train):\n",
    "                print(\"\\n\\n Using C=\", combs[i][0], \"and sigma=\", combs[i][1])\n",
    "                clf = HYP_SVM(C=combs[i][0], sigma=combs[i][1])\n",
    "                #clf = HYP_SVM(C=combs[i][0], kernel=gaussian_kernel, sigma=combs[i][1])\n",
    "                i+=1\n",
    "                #typ = 2            \n",
    "                \n",
    "                #print(len(X_train), len(X_test), len(y_train))\n",
    "                clf.m_func(X_train,X_test,y_train)\n",
    "                \n",
    "                clf.fit(X_train, y_train)\n",
    "                y_predict = clf.predict(X_test)\n",
    "                print(y_test)\n",
    "                score(y_predict,y_test)\n",
    "                correct = np.sum(y_predict == y_test)\n",
    "                mse = mean_squared_error(y_test, y_predict)\n",
    "                print(\"%d out of %d predictions correct\" % (correct, len(y_predict)))\n",
    "                print(\"Accuracy\",correct/len(y_predict))\n",
    "                print(\"Errore quadratico medio: \", mse)\n",
    "            \n",
    "    hyp_svm()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When assigning fuzzy memberships for training examples\n",
    "in the FSVM-CIL method, in order to reflect the class imbal-\n",
    "ance, we assign r + = 1, and r  = r, where r is the minority-\n",
    "to-majority class ratio. This was following the findings reported\n",
    "in [5], where the optimal results for the DEC method could\n",
    "be obtained when C  /C + equals to the minority-to-majority\n",
    "class ratio. According to this assignment of values, a positive-\n",
    "class example can take a membership value in the [0, 1] interval,\n",
    "while a negative-class example can take a membership value in\n",
    "the [0, r] interval, where r < 1.\n",
    "\n",
    "[...]\n",
    "\n",
    "selected the\n",
    "following ranges for parameters: log 2 C = {1, 2, . . . , 15}, and\n",
    "log 2  = {15, 14, . . . , 1}. First, we conducted a coarse\n",
    "grid-parameter-search to find the optimal values for log 2 C and\n",
    "log 2  over the aforementioned ranges of values. We evalu-\n",
    "ated the performance of a model trained on each parameter\n",
    "pair (log 2 C, log 2 ) by using five-fold cross-validation results\n",
    "on the training dataset. After finding the optimal values for\n",
    "the parameters, say ( C,), again, a narrow grid-parameter-\n",
    "search was conducted over the ranges log 2 C = {c  0.75, c \n",
    "0.5, . . . , c + 0.75}, and log 2  = {  0.75,   0.5, . . . ,  +\n",
    "0.75}. Finally, after finding the optimal values for (log 2 C,\n",
    "log 2 ), a new SVM model was trained by using the complete\n",
    "training dataset on these parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = svm.SVC(kernel='rbf', gamma=0.001, C=100)\n",
    "clf_svm.fit(X_train, y_train)\n",
    "y_pred_svm = clf_svm.predict(X_test) \n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print (\"Overall RBF KERNEL SVM accuracy: \",acc_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import pylab as pl           \n",
    "    def hyp_svm():\n",
    "        C_vals = [1e-2, 1e-1, 1e+1, 1e+2, 1e+3, 1e+4]\n",
    "        sigma = [9e-2, 9e-1, 9e+1, 9e+2, 9e+3, 9e+4]\n",
    "        \n",
    "        parameters = {'C': C_vals, 'sigma': sigma }\n",
    "        clf = GridSearchCV(model, parameters, cv = 5)\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "        skf2 = StratifiedKFold(n_splits=len(combs), shuffle=True, random_state=1)\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            i=0\n",
    "            for train_index, test_index in skf2.split(X_train, y_train):\n",
    "                print(\"\\n\\n Using C=\", combs[i][0], \"and sigma=\", combs[i][1])\n",
    "                clf = HYP_SVM(C=combs[i][0], kernel=gaussian_kernel, sigma=combs[i][1])\n",
    "                i+=1\n",
    "                typ = 2            \n",
    "    \n",
    "                clf.m_func(X_train,X_test,y_train)\n",
    "                clf.fit(X_train,X_test, y_train)\n",
    "                y_predict = clf.predict(X_test)\n",
    "                print(y_test)\n",
    "                gm(y_predict,y_test)\n",
    "                correct = np.sum(y_predict == y_test)\n",
    "                mse = mean_squared_error(y_test, y_predict)\n",
    "                print(\"%d out of %d predictions correct\" % (correct, len(y_predict)))\n",
    "                print(\"Accuracy\",correct/len(y_predict))\n",
    "                print(\"Errore quadratico medio: \", mse)\n",
    "            \n",
    "    hyp_svm() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 120)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  2.1631e+04 -2.2629e+05  4e+05  1e-01  3e-14\n",
      " 1:  1.2065e+04 -2.6367e+04  5e+04  1e-02  6e-14\n",
      " 2:  2.7925e+03 -4.7250e+03  8e+03  1e-03  3e-14\n",
      " 3:  3.9162e+02 -6.1240e+02  1e+03  1e-14  2e-14\n",
      " 4:  3.4389e+01 -1.0118e+02  1e+02  1e-15  8e-15\n",
      " 5: -3.9411e+00 -5.2880e+01  5e+01  2e-15  3e-15\n",
      " 6: -2.3726e+01 -4.6685e+01  2e+01  4e-16  4e-15\n",
      " 7: -2.9957e+01 -3.4971e+01  5e+00  4e-15  5e-15\n",
      " 8: -3.1334e+01 -3.2913e+01  2e+00  4e-15  3e-15\n",
      " 9: -3.1961e+01 -3.2104e+01  1e-01  1e-14  4e-15\n",
      "10: -3.2023e+01 -3.2025e+01  1e-03  1e-14  4e-15\n",
      "11: -3.2024e+01 -3.2024e+01  1e-05  6e-15  4e-15\n",
      "Optimal solution found.\n",
      "optimal\n",
      "(115,)\n",
      "(120,)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'HYP_SVM' object has no attribute 'K'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-93042925f074>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#clf.score(xTest, yTest)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#clf.best_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-e558ad21624d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Gram matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvxopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HYP_SVM' object has no attribute 'K'"
     ]
    }
   ],
   "source": [
    "C_vals = [1e-2, 1e-1, 1e+1, 1e+2, 1e+3, 1e+4]\n",
    "sigma = [9e-2, 9e-1, 9e+1, 9e+2, 9e+3, 9e+4]\n",
    "kernels = [\"linear_kernel\", \"polynomial_kernel\", \"gaussian_kernel\"]\n",
    "parameters = {'C': C_vals, 'sigma': sigma, 'kernel' : kernels }\n",
    "\n",
    "model = HYP_SVM(C=100, kernel=gaussian_kernel, sigma=0.9)\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X,y,  test_size=30)\n",
    "model.m_func(xTrain,xTest,yTrain)\n",
    "\n",
    "clf = GridSearchCV(model, parameters, cv = 5, return_train_score=True)\n",
    "\n",
    "clf.fit(xTrain, yTrain)\n",
    "#clf.score(xTest, yTest)\n",
    "#clf.best_params_\n",
    "\n",
    "#best_model = FuzzyMMC(sensitivity=0.5, exp_bound=0.60, animate=False)\n",
    "#best_model.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxopt import matrix\n",
    "class SVM(object):\n",
    "\n",
    "    def __init__(self, kernel=gaussian_kernel, C=None):\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "        if self.C is not None: self.C = float(self.C)\n",
    "    def fit(self, X, y):\n",
    "        self.kernel = gaussian_kernel\n",
    "        n_samples, n_features = X.shape\n",
    "        # Gram matrix\n",
    "        K = np.zeros((n_samples, n_samples))\n",
    "        for i in range(n_samples):\n",
    "            for j in range(n_samples):\n",
    "                K[i,j] = gaussian_kernel(X[i], X[j])\n",
    "               # print(K[i,j])\n",
    "        print(K.shape)\n",
    "\n",
    "        P = cvxopt.matrix(np.outer(y,y) * K)\n",
    "        q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
    "        A = cvxopt.matrix(y, (1,n_samples))\n",
    "        A = matrix(A, (1,n_samples), 'd') #changes done\n",
    "        b = cvxopt.matrix(0.0)\n",
    "        #print(P,q,A,b)\n",
    "        if self.C is None:\n",
    "            G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "            h = cvxopt.matrix(np.zeros(n_samples))\n",
    "            \n",
    "        else:\n",
    "            tmp1 = np.diag(np.ones(n_samples) * -1)\n",
    "            tmp2 = np.identity(n_samples)\n",
    "            G = cvxopt.matrix(np.vstack((tmp1, tmp2)))\n",
    "            tmp1 = np.zeros(n_samples)\n",
    "            tmp2 = np.ones(n_samples) * self.C\n",
    "            h = cvxopt.matrix(np.hstack((tmp1, tmp2)))\n",
    "        # solve QP problem\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "        print(solution['status'])\n",
    "        # Lagrange multipliers\n",
    "        a = np.ravel(solution['x'])\n",
    "       # print(a)\n",
    "        # Support vectors have non zero lagrange multipliers\n",
    "        sv = a > 1e-5\n",
    "        print(sv.shape)\n",
    "        ind = np.arange(len(a))[sv]\n",
    "        self.a = a[sv]\n",
    "        self.sv = X[sv]\n",
    "        self.sv_y = y[sv]\n",
    "        print(\"%d support vectors out of %d points\" % (len(self.a), n_samples))\n",
    "\n",
    "        # Intercept\n",
    "        self.b = 0\n",
    "        for n in range(len(self.a)):\n",
    "            self.b += self.sv_y[n]\n",
    "            self.b -= np.sum(self.a * self.sv_y * K[ind[n],sv])\n",
    "        self.b /= len(self.a)\n",
    "\n",
    "        # Weight vector\n",
    "        if self.kernel == gaussian_kernel:\n",
    "            self.w = np.zeros(n_features)\n",
    "            for n in range(len(self.a)):\n",
    "                self.w += self.a[n] * self.sv_y[n] * self.sv[n]\n",
    "                #print(self.w)\n",
    "        else:\n",
    "            self.w = None\n",
    "\n",
    "    def project(self, X):\n",
    "        if self.w is None:\n",
    "            return np.dot(X, self.w) + self.b\n",
    "        else:\n",
    "            y_predict = np.zeros(len(X))\n",
    "            X=np.asarray(X)\n",
    "            for i in range(len(X)):\n",
    "                s = 0\n",
    "                for a, sv_y, sv in zip(self.a, self.sv_y, self.sv):\n",
    "                    s += a * sv_y * gaussian_kernel(X[i], sv)\n",
    "                y_predict[i] = s\n",
    "              #  print(y_predict[i])\n",
    "            return y_predict + self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.project(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import pylab as pl           \n",
    "    def normal_svm():\n",
    "        \n",
    "        clf = SVM(C=100.0)\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            #print(\"TRAIN:\", train_index, \"\\nTEST:\", test_index)\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            clf.fit(X_train, y_train)    \n",
    "            y_predict = clf.predict(X_test)\n",
    "            gm(y_predict,y_test)\n",
    "            correct = np.sum(y_predict == y_test)\n",
    "            mse = mean_squared_error(y_test, y_predict)\n",
    "            print(\"%d out of %d predictions correct\" % (correct, len(y_predict)))\n",
    "            print(\"Accuracy\",correct/len(y_predict))\n",
    "            print(\"Errore quadratico medio: \", mse)\n",
    "    normal_svm()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
