{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from cvxopt import matrix as cvxopt_matrix\n",
    "from cvxopt import solvers as cvxopt_solvers\n",
    "from sklearn import svm\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.9365</td>\n",
       "      <td>0.3940</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.6390</td>\n",
       "      <td>0.6055</td>\n",
       "      <td>0.2805</td>\n",
       "      <td>0.460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0075</td>\n",
       "      <td>0.4425</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.8115</td>\n",
       "      <td>0.3410</td>\n",
       "      <td>0.1675</td>\n",
       "      <td>0.255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3       4       5       6      7  8\n",
       "0  1  0.455  0.365  0.095  0.5140  0.2245  0.1010  0.150  1\n",
       "1  1  0.605  0.475  0.180  0.9365  0.3940  0.2190  0.295  1\n",
       "2  2  0.680  0.560  0.165  1.6390  0.6055  0.2805  0.460  1\n",
       "3  2  0.600  0.475  0.150  1.0075  0.4425  0.2210  0.280  1\n",
       "4  1  0.565  0.425  0.135  0.8115  0.3410  0.1675  0.255  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"modifiedabalone.csv\", header=None)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.9365</td>\n",
       "      <td>0.3940</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.2950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.6390</td>\n",
       "      <td>0.6055</td>\n",
       "      <td>0.2805</td>\n",
       "      <td>0.4600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0075</td>\n",
       "      <td>0.4425</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.8115</td>\n",
       "      <td>0.3410</td>\n",
       "      <td>0.1675</td>\n",
       "      <td>0.2550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>2</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>1</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>1</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>2</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>1</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2      3       4       5       6       7\n",
       "0     1  0.455  0.365  0.095  0.5140  0.2245  0.1010  0.1500\n",
       "1     1  0.605  0.475  0.180  0.9365  0.3940  0.2190  0.2950\n",
       "2     2  0.680  0.560  0.165  1.6390  0.6055  0.2805  0.4600\n",
       "3     2  0.600  0.475  0.150  1.0075  0.4425  0.2210  0.2800\n",
       "4     1  0.565  0.425  0.135  0.8115  0.3410  0.1675  0.2550\n",
       "...  ..    ...    ...    ...     ...     ...     ...     ...\n",
       "4172  2  0.565  0.450  0.165  0.8870  0.3700  0.2390  0.2490\n",
       "4173  1  0.590  0.440  0.135  0.9660  0.4390  0.2145  0.2605\n",
       "4174  1  0.600  0.475  0.205  1.1760  0.5255  0.2875  0.3080\n",
       "4175  2  0.625  0.485  0.150  1.0945  0.5310  0.2610  0.2960\n",
       "4176  1  0.710  0.555  0.195  1.9485  0.9455  0.3765  0.4950\n",
       "\n",
       "[4177 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = train.columns[0:8]\n",
    "X = train[features]\n",
    "y = train[8]\n",
    "#X.head()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3341, 8) (836, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.     0.57   0.42   0.13   0.7745 0.3535 0.1505 0.2365]\n",
      " [1.     0.495  0.4    0.12   0.6605 0.2605 0.161  0.19  ]\n",
      " [3.     0.52   0.4    0.13   0.5825 0.233  0.1365 0.18  ]\n",
      " [2.     0.485  0.365  0.12   0.5885 0.27   0.131  0.175 ]\n",
      " [2.     0.38   0.32   0.115  0.6475 0.323  0.1325 0.164 ]\n",
      " [2.     0.7    0.525  0.19   1.6015 0.707  0.365  0.43  ]\n",
      " [3.     0.525  0.385  0.13   0.607  0.2355 0.125  0.195 ]\n",
      " [1.     0.495  0.385  0.135  0.709  0.211  0.1375 0.262 ]\n",
      " [2.     0.635  0.475  0.15   1.1845 0.533  0.307  0.291 ]\n",
      " [2.     0.55   0.405  0.125  0.651  0.2965 0.137  0.2   ]\n",
      " [2.     0.625  0.5    0.16   1.217  0.5725 0.207  0.355 ]\n",
      " [1.     0.615  0.5    0.17   1.054  0.4845 0.228  0.295 ]\n",
      " [3.     0.535  0.4    0.135  0.775  0.368  0.208  0.2055]\n",
      " [3.     0.175  0.125  0.05   0.0235 0.008  0.0035 0.008 ]\n",
      " [1.     0.595  0.485  0.15   1.0835 0.5305 0.231  0.276 ]\n",
      " [1.     0.62   0.495  0.175  1.806  0.643  0.3285 0.725 ]\n",
      " [3.     0.475  0.38   0.12   0.441  0.1785 0.0885 0.1505]\n",
      " [1.     0.575  0.45   0.165  0.9655 0.498  0.19   0.23  ]\n",
      " [2.     0.595  0.45   0.165  1.081  0.49   0.2525 0.279 ]\n",
      " [3.     0.605  0.48   0.155  0.9995 0.425  0.1985 0.3   ]\n",
      " [3.     0.36   0.3    0.085  0.27   0.1185 0.064  0.0745]\n",
      " [1.     0.51   0.41   0.155  1.2825 0.569  0.291  0.3795]\n",
      " [2.     0.385  0.3    0.1    0.2725 0.1115 0.057  0.08  ]\n",
      " [3.     0.34   0.25   0.07   0.2225 0.104  0.0425 0.055 ]\n",
      " [2.     0.73   0.58   0.19   1.7375 0.6785 0.4345 0.52  ]\n",
      " [1.     0.46   0.38   0.135  0.482  0.207  0.1225 0.145 ]\n",
      " [1.     0.54   0.41   0.13   0.56   0.2375 0.1065 0.175 ]\n",
      " [1.     0.585  0.465  0.16   0.9555 0.4595 0.236  0.265 ]\n",
      " [1.     0.665  0.525  0.18   1.429  0.6715 0.29   0.4   ]\n",
      " [2.     0.57   0.465  0.18   0.9995 0.405  0.277  0.295 ]\n",
      " [2.     0.475  0.375  0.15   0.559  0.1955 0.1215 0.1945]\n",
      " [2.     0.64   0.505  0.175  1.3185 0.6185 0.302  0.3315]\n",
      " [1.     0.595  0.475  0.165  1.213  0.621  0.2435 0.274 ]\n",
      " [1.     0.57   0.48   0.18   0.9395 0.399  0.2    0.295 ]\n",
      " [3.     0.435  0.345  0.115  0.418  0.222  0.0735 0.106 ]\n",
      " [2.     0.64   0.54   0.175  1.571  0.627  0.271  0.475 ]\n",
      " [3.     0.285  0.22   0.065  0.096  0.0405 0.0205 0.03  ]\n",
      " [3.     0.44   0.325  0.11   0.4965 0.258  0.1195 0.1075]\n",
      " [1.     0.67   0.525  0.195  1.4405 0.6595 0.2675 0.425 ]\n",
      " [3.     0.34   0.265  0.07   0.185  0.0625 0.0395 0.07  ]\n",
      " [1.     0.63   0.47   0.15   1.1355 0.539  0.2325 0.3115]\n",
      " [1.     0.545  0.425  0.135  0.8445 0.373  0.21   0.235 ]\n",
      " [1.     0.59   0.47   0.15   0.861  0.413  0.164  0.249 ]\n",
      " [1.     0.445  0.355  0.11   0.4415 0.1805 0.1035 0.1505]\n",
      " [3.     0.58   0.445  0.15   0.8865 0.383  0.209  0.255 ]\n",
      " [1.     0.585  0.455  0.155  1.133  0.5515 0.223  0.305 ]\n",
      " [1.     0.625  0.495  0.185  1.3835 0.7105 0.3005 0.345 ]\n",
      " [2.     0.72   0.575  0.195  2.1505 1.0745 0.382  0.585 ]\n",
      " [2.     0.36   0.265  0.09   0.2065 0.078  0.057  0.06  ]\n",
      " [1.     0.715  0.55   0.19   2.0045 1.0465 0.407  0.5075]\n",
      " [3.     0.37   0.29   0.09   0.2445 0.089  0.0655 0.075 ]\n",
      " [3.     0.635  0.5    0.18   1.319  0.5485 0.292  0.49  ]\n",
      " [2.     0.65   0.505  0.165  1.16   0.4785 0.274  0.349 ]\n",
      " [2.     0.67   0.525  0.195  1.42   0.573  0.368  0.3905]\n",
      " [1.     0.66   0.485  0.155  1.2275 0.61   0.274  0.3   ]]\n"
     ]
    }
   ],
   "source": [
    "X_train=np.asarray(X_train)\n",
    "y_train=np.asarray(y_train)\n",
    "print(X_train[75:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, x2)\n",
    "\n",
    "def polynomial_kernel(x, y, p=3):\n",
    "    return (1 + np.dot(x, y)) ** p\n",
    "\n",
    "def gaussian_kernel(x, y, sigma=10.0):\n",
    "   # print(-linalg.norm(x-y)**2)\n",
    "    x=np.asarray(x)\n",
    "    y=np.asarray(y)\n",
    "    return np.exp((-linalg.norm(x-y)**2) / (2 * (sigma ** 2)))\n",
    "\n",
    "def gm(y_predict,y_test):\n",
    "    test_min=0\n",
    "    test_max=0\n",
    "    pred_min=0\n",
    "    pred_max=0\n",
    "    y_test=np.asarray(y_test)\n",
    "    for i in range(0,836):\n",
    "        if(y_test[i]==1):\n",
    "             test_min=test_min+1\n",
    "        else:\n",
    "             test_max=test_max+1\n",
    "    print(\"y_test min\",test_min)       \n",
    "    print(\"y_test max\",test_max)\n",
    "    for i in range(0,836):\n",
    "        if(y_predict[i]==1 and y_predict[i]==y_test[i]):\n",
    "             pred_min=pred_min+1\n",
    "        elif(y_predict[i]==-1 and y_predict[i]==y_test[i]):\n",
    "             pred_max=pred_max+1\n",
    "    print(\"y_pred min\",pred_min)       \n",
    "    print(\"y_pred max\",pred_max)\n",
    "    se=pred_min/test_min\n",
    "    sp=pred_max/test_max\n",
    "    print(se,sp)\n",
    "    gm=math.sqrt(se*sp)\n",
    "    print(\"GM\",gm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FSVM using Hyperplane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxopt import matrix\n",
    "class HYP_SVM(object):\n",
    "\n",
    "    def __init__(self, kernel=gaussian_kernel, C=None):\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "        if self.C is not None: self.C = float(self.C)\n",
    "    def m_func(self, X_train,X_test, y):\n",
    "        n_samples, n_features = X_train.shape \n",
    "        nt_samples, nt_features= X_test.shape\n",
    "        self.K = np.zeros((n_samples, n_samples))\n",
    "        for i in range(n_samples):\n",
    "            for j in range(n_samples):\n",
    "                self.K[i,j] = gaussian_kernel(X_train[i], X_train[j])\n",
    "               # print(K[i,j])\n",
    "        X_train=np.asarray(X_train)\n",
    "        X_test=np.asarray(X_test)\n",
    "        K1 = np.zeros((n_samples, n_samples))\n",
    "        for i in range(n_samples):\n",
    "            for j in range(n_samples):\n",
    "                K1[i,j] = gaussian_kernel(X_train[i], X_train[j])\n",
    "               # print(K[i,j])\n",
    "        print(K1.shape)\n",
    "        P = cvxopt.matrix(np.outer(y,y) * self.K)\n",
    "        q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
    "        A = cvxopt.matrix(y, (1,n_samples))\n",
    "        A = matrix(A, (1,n_samples), 'd') #changes done\n",
    "        b = cvxopt.matrix(0.0)\n",
    "        #print(P,q,A,b)\n",
    "        if self.C is None:\n",
    "            G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "            h = cvxopt.matrix(np.zeros(n_samples))\n",
    "            \n",
    "        else:\n",
    "            tmp1 = np.diag(np.ones(n_samples) * -1)\n",
    "            tmp2 = np.identity(n_samples)\n",
    "            G = cvxopt.matrix(np.vstack((tmp1, tmp2)))\n",
    "            tmp1 = np.zeros(n_samples)\n",
    "            tmp2 = np.ones(n_samples) * self.C\n",
    "            h = cvxopt.matrix(np.hstack((tmp1, tmp2)))\n",
    "        # solve QP problem\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "        print(solution['status'])\n",
    "        # Lagrange multipliers\n",
    "        a = np.ravel(solution['x'])\n",
    "        a_org = np.ravel(solution['x'])\n",
    "        # Support vectors have non zero lagrange multipliers\n",
    "        sv = a > 1e-5\n",
    "        #print(sv.shape)\n",
    "        ind = np.arange(len(a))[sv]\n",
    "        self.a_org=a\n",
    "        self.a = a[sv]\n",
    "        self.sv = X_train[sv]\n",
    "        self.sv_y = y[sv]\n",
    "        self.sv_yorg=y\n",
    "        self.kernel = gaussian_kernel\n",
    "        X_train=np.asarray(X_train)\n",
    "        b = 0\n",
    "        for n in range(len(self.a)):\n",
    "            b += self.sv_y[n]\n",
    "            b -= np.sum(self.a * self.sv_y * self.K[ind[n],sv])\n",
    "        b /= len(self.a)\n",
    "       # print(self.a_org[1])\n",
    "        #print(self.a_org.shape,self.sv_yorg.shape,K.shape)\n",
    "        w_phi=0\n",
    "        total=0\n",
    "        for n in range(len(self.a_org)):\n",
    "            w_phi = self.a_org[n] * self.sv_yorg[n] * K1[n] \n",
    "        self.d_hyp=np.zeros(n_samples)\n",
    "        for n in range(len(self.a_org)):\n",
    "            self.d_hyp += self.sv_yorg[n]*(w_phi+b)\n",
    "        func=np.zeros((n_samples))\n",
    "        func=np.asarray(func)\n",
    "        typ=1\n",
    "        if(typ==1):\n",
    "            for i in range(n_samples):\n",
    "                func[i]=1-(self.d_hyp[i]/(np.amax(self.d_hyp[i])+0.000001))\n",
    "        beta=0.2\n",
    "        if(typ==2):\n",
    "            for i in range(n_samples):\n",
    "                func[i]=2/(1+beta*self.d_hyp[i])\n",
    "        r_max=103/4074\n",
    "        r_min=1\n",
    "        self.m=func[0:103]*r_min\n",
    "        print(self.m.shape)\n",
    "        self.m=np.append(self.m,func[103:4177]*r_max)\n",
    "        print(self.m.shape)\n",
    "        \n",
    " ##############################################################################\n",
    "\n",
    "\n",
    "    def fit(self, X_train,X_test, y):\n",
    "        self.kernel = gaussian_kernel\n",
    "        n_samples, n_features = X_train.shape \n",
    "        nt_samples, nt_features = X_test.shape\n",
    "        # Gram matrix\n",
    "\n",
    "        print(self.K.shape)\n",
    "\n",
    "        P = cvxopt.matrix(np.outer(y,y) * self.K)\n",
    "        q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
    "        A = cvxopt.matrix(y, (1,n_samples))\n",
    "        A = matrix(A, (1,n_samples), 'd') #changes done\n",
    "        b = cvxopt.matrix(0.0)\n",
    "        #print(P,q,A,b)\n",
    "        if self.C is None:\n",
    "            G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "            h = cvxopt.matrix(np.zeros(n_samples))\n",
    "            \n",
    "        else:\n",
    "            tmp1 = np.diag(np.ones(n_samples) * -1)\n",
    "            tmp2 = np.identity(n_samples)\n",
    "            G = cvxopt.matrix(np.vstack((tmp1, tmp2)))\n",
    "            tmp1 = np.zeros(n_samples)\n",
    "            tmp2 = np.ones(n_samples) * self.C\n",
    "            h = cvxopt.matrix(np.hstack((tmp1, tmp2)))\n",
    "        # solve QP problem\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "        print(solution['status'])\n",
    "        # Lagrange multipliers\n",
    "        a = np.ravel(solution['x'])\n",
    "        a_org = np.ravel(solution['x'])\n",
    "        # Support vectors have non zero lagrange multipliers\n",
    "        for i in range(n_samples):\n",
    "            sv=np.logical_or(self.a_org <self.m, self.a_org > 1e-5)\n",
    "        #print(sv.shape)\n",
    "        ind = np.arange(len(a))[sv]\n",
    "        self.a = a[sv]\n",
    "        self.sv = X_train[sv]\n",
    "        self.sv_y = y[sv]\n",
    "        #print(\"%d support vectors out of %d points\" % (len(self.a), n_samples))\n",
    "\n",
    "        # Intercept\n",
    "        self.b = 0\n",
    "        for n in range(len(self.a)):\n",
    "            self.b += self.sv_y[n]\n",
    "            self.b -= np.sum(self.a * self.sv_y * self.K[ind[n],sv])\n",
    "        self.b /= len(self.a)\n",
    "        print(self.b)\n",
    "\n",
    "        # Weight vector\n",
    "        if self.kernel == gaussian_kernel:\n",
    "            self.w = np.zeros(n_features)\n",
    "            for n in range(len(self.a)):\n",
    "                self.w += self.a[n] * self.sv_y[n] * self.sv[n]\n",
    "        else :\n",
    "            self.w = None        \n",
    "        \n",
    "    def project(self, X):\n",
    "        if self.w is None:\n",
    "            return np.dot(X, self.w) + self.b\n",
    "        else:\n",
    "            y_predict = np.zeros(len(X))\n",
    "            X=np.asarray(X)\n",
    "            for i in range(len(X)):\n",
    "                s = 0\n",
    "                for a, sv_y, sv in zip(self.a, self.sv_y, self.sv):\n",
    "                    s += a * sv_y * gaussian_kernel(X[i], sv)\n",
    "                y_predict[i] = s\n",
    "              #  print(y_predict[i])\n",
    "            return y_predict + self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.project(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3341, 3341)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.4904e+04 -2.0036e+06  2e+06  2e-02  8e-13\n",
      " 1: -1.3268e+04 -1.4210e+05  1e+05  4e-04  8e-13\n",
      " 2: -1.5305e+04 -5.5521e+04  4e+04  3e-05  8e-13\n",
      " 3: -1.5484e+04 -5.3758e+04  4e+04  3e-05  8e-13\n",
      " 4: -1.6200e+04 -3.0338e+04  1e+04  5e-06  8e-13\n",
      " 5: -1.6293e+04 -2.9163e+04  1e+04  3e-06  7e-13\n",
      " 6: -1.6519e+04 -2.4440e+04  8e+03  1e-06  8e-13\n",
      " 7: -1.6658e+04 -2.0918e+04  4e+03  6e-07  7e-13\n",
      " 8: -1.6753e+04 -1.8317e+04  2e+03  2e-07  7e-13\n",
      " 9: -1.6785e+04 -1.7377e+04  6e+02  5e-08  7e-13\n",
      "10: -1.6797e+04 -1.6906e+04  1e+02  5e-09  8e-13\n",
      "11: -1.6799e+04 -1.6829e+04  3e+01  8e-11  8e-13\n",
      "12: -1.6799e+04 -1.6820e+04  2e+01  4e-11  7e-13\n",
      "13: -1.6800e+04 -1.6806e+04  6e+00  9e-12  8e-13\n",
      "14: -1.6800e+04 -1.6805e+04  6e+00  7e-12  8e-13\n",
      "15: -1.6800e+04 -1.6803e+04  4e+00  5e-13  9e-13\n",
      "16: -1.6800e+04 -1.6802e+04  2e+00  2e-13  8e-13\n",
      "17: -1.6800e+04 -1.6801e+04  1e+00  3e-13  7e-13\n",
      "18: -1.6800e+04 -1.6801e+04  1e+00  2e-13  7e-13\n",
      "19: -1.6800e+04 -1.6801e+04  9e-01  2e-13  7e-13\n",
      "20: -1.6800e+04 -1.6801e+04  8e-01  9e-13  7e-13\n",
      "21: -1.6800e+04 -1.6800e+04  3e-01  1e-12  7e-13\n",
      "22: -1.6800e+04 -1.6800e+04  1e-01  1e-12  8e-13\n",
      "23: -1.6800e+04 -1.6800e+04  8e-02  2e-16  7e-13\n",
      "24: -1.6800e+04 -1.6800e+04  2e-02  5e-13  7e-13\n",
      "25: -1.6800e+04 -1.6800e+04  1e-02  9e-14  7e-13\n",
      "Optimal solution found.\n",
      "optimal\n",
      "(103,)\n",
      "(3341,)\n",
      "(3341, 3341)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.4904e+04 -2.0036e+06  2e+06  2e-02  8e-13\n",
      " 1: -1.3268e+04 -1.4210e+05  1e+05  4e-04  8e-13\n",
      " 2: -1.5305e+04 -5.5521e+04  4e+04  3e-05  8e-13\n",
      " 3: -1.5484e+04 -5.3758e+04  4e+04  3e-05  8e-13\n",
      " 4: -1.6200e+04 -3.0338e+04  1e+04  5e-06  8e-13\n",
      " 5: -1.6293e+04 -2.9163e+04  1e+04  3e-06  7e-13\n",
      " 6: -1.6519e+04 -2.4440e+04  8e+03  1e-06  8e-13\n",
      " 7: -1.6658e+04 -2.0918e+04  4e+03  6e-07  7e-13\n",
      " 8: -1.6753e+04 -1.8317e+04  2e+03  2e-07  7e-13\n",
      " 9: -1.6785e+04 -1.7377e+04  6e+02  5e-08  7e-13\n",
      "10: -1.6797e+04 -1.6906e+04  1e+02  5e-09  8e-13\n",
      "11: -1.6799e+04 -1.6829e+04  3e+01  8e-11  8e-13\n",
      "12: -1.6799e+04 -1.6820e+04  2e+01  4e-11  7e-13\n",
      "13: -1.6800e+04 -1.6806e+04  6e+00  9e-12  8e-13\n",
      "14: -1.6800e+04 -1.6805e+04  6e+00  7e-12  8e-13\n",
      "15: -1.6800e+04 -1.6803e+04  4e+00  5e-13  9e-13\n",
      "16: -1.6800e+04 -1.6802e+04  2e+00  2e-13  8e-13\n",
      "17: -1.6800e+04 -1.6801e+04  1e+00  3e-13  7e-13\n",
      "18: -1.6800e+04 -1.6801e+04  1e+00  2e-13  7e-13\n",
      "19: -1.6800e+04 -1.6801e+04  9e-01  2e-13  7e-13\n",
      "20: -1.6800e+04 -1.6801e+04  8e-01  9e-13  7e-13\n",
      "21: -1.6800e+04 -1.6800e+04  3e-01  1e-12  7e-13\n",
      "22: -1.6800e+04 -1.6800e+04  1e-01  1e-12  8e-13\n",
      "23: -1.6800e+04 -1.6800e+04  8e-02  2e-16  7e-13\n",
      "24: -1.6800e+04 -1.6800e+04  2e-02  5e-13  7e-13\n",
      "25: -1.6800e+04 -1.6800e+04  1e-02  9e-14  7e-13\n",
      "Optimal solution found.\n",
      "optimal\n",
      "-0.9564844679185212\n",
      "y_test min 19\n",
      "y_test max 817\n",
      "y_pred min 0\n",
      "y_pred max 817\n",
      "0.0 1.0\n",
      "GM 0.0\n",
      "817 out of 836 predictions correct\n",
      "Accuracy 0.9772727272727273\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import pylab as pl           \n",
    "    def hyp_svm():\n",
    "        \n",
    "        clf = HYP_SVM(C=100.0)\n",
    "        typ=2\n",
    "        clf.m_func(X_train,X_test,y_train)\n",
    "        clf.fit(X_train,X_test, y_train)\n",
    "        y_predict = clf.predict(X_test)\n",
    "        gm(y_predict,y_test)\n",
    "        correct = np.sum(y_predict == y_test)\n",
    "        print(\"%d out of %d predictions correct\" % (correct, len(y_predict)))\n",
    "        print(\"Accuracy\",correct/len(y_predict))\n",
    "\n",
    "    hyp_svm()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall RBF KERNEL SVM accuracy:  0.9772727272727273\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(kernel='rbf', gamma=0.001, C=100)\n",
    "clf_svm.fit(X_train, y_train)\n",
    "y_pred_svm = clf_svm.predict(X_test) \n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print (\"Overall RBF KERNEL SVM accuracy: \",acc_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal SVM using CVXOPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxopt import matrix\n",
    "class SVM(object):\n",
    "\n",
    "    def __init__(self, kernel=gaussian_kernel, C=None):\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "        if self.C is not None: self.C = float(self.C)\n",
    "    def fit(self, X, y):\n",
    "        self.kernel = gaussian_kernel\n",
    "        n_samples, n_features = X.shape\n",
    "        # Gram matrix\n",
    "        K = np.zeros((n_samples, n_samples))\n",
    "        for i in range(n_samples):\n",
    "            for j in range(n_samples):\n",
    "                K[i,j] = gaussian_kernel(X[i], X[j])\n",
    "               # print(K[i,j])\n",
    "        print(K.shape)\n",
    "\n",
    "        P = cvxopt.matrix(np.outer(y,y) * K)\n",
    "        q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
    "        A = cvxopt.matrix(y, (1,n_samples))\n",
    "        A = matrix(A, (1,n_samples), 'd') #changes done\n",
    "        b = cvxopt.matrix(0.0)\n",
    "        #print(P,q,A,b)\n",
    "        if self.C is None:\n",
    "            G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "            h = cvxopt.matrix(np.zeros(n_samples))\n",
    "            \n",
    "        else:\n",
    "            tmp1 = np.diag(np.ones(n_samples) * -1)\n",
    "            tmp2 = np.identity(n_samples)\n",
    "            G = cvxopt.matrix(np.vstack((tmp1, tmp2)))\n",
    "            tmp1 = np.zeros(n_samples)\n",
    "            tmp2 = np.ones(n_samples) * self.C\n",
    "            h = cvxopt.matrix(np.hstack((tmp1, tmp2)))\n",
    "        # solve QP problem\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "        print(solution['status'])\n",
    "        # Lagrange multipliers\n",
    "        a = np.ravel(solution['x'])\n",
    "       # print(a)\n",
    "        # Support vectors have non zero lagrange multipliers\n",
    "        sv = a > 1e-5\n",
    "        print(sv.shape)\n",
    "        ind = np.arange(len(a))[sv]\n",
    "        self.a = a[sv]\n",
    "        self.sv = X[sv]\n",
    "        self.sv_y = y[sv]\n",
    "        print(\"%d support vectors out of %d points\" % (len(self.a), n_samples))\n",
    "\n",
    "        # Intercept\n",
    "        self.b = 0\n",
    "        for n in range(len(self.a)):\n",
    "            self.b += self.sv_y[n]\n",
    "            self.b -= np.sum(self.a * self.sv_y * K[ind[n],sv])\n",
    "        self.b /= len(self.a)\n",
    "\n",
    "        # Weight vector\n",
    "        if self.kernel == gaussian_kernel:\n",
    "            self.w = np.zeros(n_features)\n",
    "            for n in range(len(self.a)):\n",
    "                self.w += self.a[n] * self.sv_y[n] * self.sv[n]\n",
    "                #print(self.w)\n",
    "        else:\n",
    "            self.w = None\n",
    "\n",
    "    def project(self, X):\n",
    "        if self.w is None:\n",
    "            return np.dot(X, self.w) + self.b\n",
    "        else:\n",
    "            y_predict = np.zeros(len(X))\n",
    "            X=np.asarray(X)\n",
    "            for i in range(len(X)):\n",
    "                s = 0\n",
    "                for a, sv_y, sv in zip(self.a, self.sv_y, self.sv):\n",
    "                    s += a * sv_y * gaussian_kernel(X[i], sv)\n",
    "                y_predict[i] = s\n",
    "              #  print(y_predict[i])\n",
    "            return y_predict + self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.project(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3341, 3341)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.4904e+04 -2.0036e+06  2e+06  2e-02  8e-13\n",
      " 1: -1.3268e+04 -1.4210e+05  1e+05  4e-04  8e-13\n",
      " 2: -1.5305e+04 -5.5521e+04  4e+04  3e-05  8e-13\n",
      " 3: -1.5484e+04 -5.3758e+04  4e+04  3e-05  8e-13\n",
      " 4: -1.6200e+04 -3.0338e+04  1e+04  5e-06  8e-13\n",
      " 5: -1.6293e+04 -2.9163e+04  1e+04  3e-06  7e-13\n",
      " 6: -1.6519e+04 -2.4440e+04  8e+03  1e-06  8e-13\n",
      " 7: -1.6658e+04 -2.0918e+04  4e+03  6e-07  7e-13\n",
      " 8: -1.6753e+04 -1.8317e+04  2e+03  2e-07  7e-13\n",
      " 9: -1.6785e+04 -1.7377e+04  6e+02  5e-08  7e-13\n",
      "10: -1.6797e+04 -1.6906e+04  1e+02  5e-09  8e-13\n",
      "11: -1.6799e+04 -1.6829e+04  3e+01  8e-11  8e-13\n",
      "12: -1.6799e+04 -1.6820e+04  2e+01  4e-11  7e-13\n",
      "13: -1.6800e+04 -1.6806e+04  6e+00  9e-12  8e-13\n",
      "14: -1.6800e+04 -1.6805e+04  6e+00  7e-12  8e-13\n",
      "15: -1.6800e+04 -1.6803e+04  4e+00  5e-13  9e-13\n",
      "16: -1.6800e+04 -1.6802e+04  2e+00  2e-13  8e-13\n",
      "17: -1.6800e+04 -1.6801e+04  1e+00  3e-13  7e-13\n",
      "18: -1.6800e+04 -1.6801e+04  1e+00  2e-13  7e-13\n",
      "19: -1.6800e+04 -1.6801e+04  9e-01  2e-13  7e-13\n",
      "20: -1.6800e+04 -1.6801e+04  8e-01  9e-13  7e-13\n",
      "21: -1.6800e+04 -1.6800e+04  3e-01  1e-12  7e-13\n",
      "22: -1.6800e+04 -1.6800e+04  1e-01  1e-12  8e-13\n",
      "23: -1.6800e+04 -1.6800e+04  8e-02  2e-16  7e-13\n",
      "24: -1.6800e+04 -1.6800e+04  2e-02  5e-13  7e-13\n",
      "25: -1.6800e+04 -1.6800e+04  1e-02  9e-14  7e-13\n",
      "Optimal solution found.\n",
      "optimal\n",
      "(3341,)\n",
      "3341 support vectors out of 3341 points\n",
      "y_test min 19\n",
      "y_test max 817\n",
      "y_pred min 0\n",
      "y_pred max 817\n",
      "0.0 1.0\n",
      "GM 0.0\n",
      "817 out of 836 predictions correct\n",
      "Accuracy 0.9772727272727273\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import pylab as pl           \n",
    "    def normal_svm():\n",
    "        \n",
    "        clf = SVM(C=100.0)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_predict = clf.predict(X_test)\n",
    "        gm(y_predict,y_test)\n",
    "        correct = np.sum(y_predict == y_test)\n",
    "        print(\"%d out of %d predictions correct\" % (correct, len(y_predict)))\n",
    "        print(\"Accuracy\",correct/len(y_predict))\n",
    "\n",
    "    normal_svm()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
