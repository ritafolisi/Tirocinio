{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzy import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.9, 3.1],\n",
       "       [4.8, 3.4],\n",
       "       [5.7, 3.8],\n",
       "       [6.8, 3. ],\n",
       "       [5.4, 3.4],\n",
       "       [6. , 2.9],\n",
       "       [6.9, 3.1],\n",
       "       [4.4, 3. ],\n",
       "       [5.1, 3.7],\n",
       "       [5.5, 2.4],\n",
       "       [6.3, 2.5],\n",
       "       [7.9, 3.8],\n",
       "       [6.3, 2.8],\n",
       "       [5.4, 3.4],\n",
       "       [6.2, 2.8],\n",
       "       [4.9, 3.1],\n",
       "       [6.4, 3.2],\n",
       "       [7.4, 2.8],\n",
       "       [5.9, 3. ],\n",
       "       [4.8, 3.4],\n",
       "       [6. , 2.2],\n",
       "       [5.2, 3.5],\n",
       "       [6.8, 3.2],\n",
       "       [5.4, 3.9],\n",
       "       [6. , 2.2],\n",
       "       [5. , 3.6],\n",
       "       [4.7, 3.2],\n",
       "       [5.6, 2.5],\n",
       "       [4.6, 3.2],\n",
       "       [5.8, 2.7],\n",
       "       [6.7, 3. ],\n",
       "       [6.1, 2.9],\n",
       "       [4.5, 2.3],\n",
       "       [7. , 3.2],\n",
       "       [7.2, 3.6],\n",
       "       [6.8, 2.8],\n",
       "       [5.9, 3. ],\n",
       "       [5.7, 2.9],\n",
       "       [6.3, 3.3],\n",
       "       [5.8, 4. ],\n",
       "       [5.7, 2.5],\n",
       "       [6.4, 2.8],\n",
       "       [4.9, 3.1],\n",
       "       [5.1, 3.4],\n",
       "       [5.5, 3.5],\n",
       "       [6.4, 3.2],\n",
       "       [5.9, 3.2],\n",
       "       [5. , 3.4],\n",
       "       [5.6, 3. ],\n",
       "       [6.3, 2.5],\n",
       "       [4.3, 3. ],\n",
       "       [6.7, 3.1],\n",
       "       [6.6, 3. ],\n",
       "       [5. , 3.4],\n",
       "       [6.3, 2.9],\n",
       "       [5. , 3.5],\n",
       "       [5.8, 2.6],\n",
       "       [5.5, 2.5],\n",
       "       [6.2, 2.2],\n",
       "       [7.7, 3. ],\n",
       "       [6.1, 3. ],\n",
       "       [6. , 3. ],\n",
       "       [5. , 3. ],\n",
       "       [4.6, 3.1],\n",
       "       [5.2, 4.1],\n",
       "       [5.7, 3. ],\n",
       "       [5.6, 2.9],\n",
       "       [6.7, 3. ],\n",
       "       [6.9, 3.1],\n",
       "       [5.3, 3.7],\n",
       "       [6.9, 3.2],\n",
       "       [6.5, 3. ],\n",
       "       [6.7, 3.1],\n",
       "       [4.9, 2.4],\n",
       "       [6. , 2.7],\n",
       "       [6.4, 3.1],\n",
       "       [5.5, 4.2],\n",
       "       [5.1, 3.8],\n",
       "       [6.3, 2.7],\n",
       "       [6.1, 2.8],\n",
       "       [4.7, 3.2],\n",
       "       [7.7, 2.8],\n",
       "       [6.7, 3.3],\n",
       "       [6.4, 2.9],\n",
       "       [5.8, 2.7],\n",
       "       [4.4, 3.2],\n",
       "       [6.6, 2.9],\n",
       "       [6.2, 3.4],\n",
       "       [6.7, 3.1],\n",
       "       [7.6, 3. ],\n",
       "       [6.4, 2.7],\n",
       "       [5. , 3.3],\n",
       "       [6.1, 2.8],\n",
       "       [5.5, 2.3],\n",
       "       [5.4, 3.9],\n",
       "       [5.4, 3.7],\n",
       "       [7.2, 3. ],\n",
       "       [6.3, 2.3],\n",
       "       [5.6, 3. ],\n",
       "       [6.5, 3.2],\n",
       "       [5.6, 2.7],\n",
       "       [5.5, 2.6],\n",
       "       [6.5, 3. ],\n",
       "       [6.3, 3.4],\n",
       "       [4.6, 3.4],\n",
       "       [7.3, 2.9],\n",
       "       [5.6, 2.8],\n",
       "       [7.7, 2.6],\n",
       "       [6.3, 3.3],\n",
       "       [5.5, 2.4],\n",
       "       [6.4, 2.8],\n",
       "       [7.1, 3. ],\n",
       "       [5.1, 3.5],\n",
       "       [5. , 2. ],\n",
       "       [5.7, 2.6],\n",
       "       [4.9, 2.5],\n",
       "       [4.8, 3. ],\n",
       "       [6.2, 2.9],\n",
       "       [6.7, 3.3],\n",
       "       [5.8, 2.7],\n",
       "       [5. , 3.5],\n",
       "       [5.8, 2.7],\n",
       "       [5.1, 2.5],\n",
       "       [4.4, 2.9],\n",
       "       [6.5, 2.8],\n",
       "       [5. , 2.3],\n",
       "       [6.5, 3. ],\n",
       "       [5.1, 3.3],\n",
       "       [4.8, 3. ],\n",
       "       [5.1, 3.5],\n",
       "       [5.2, 3.4],\n",
       "       [5.7, 2.8],\n",
       "       [5. , 3.2],\n",
       "       [5.8, 2.8],\n",
       "       [5.1, 3.8],\n",
       "       [5.7, 2.8],\n",
       "       [5.7, 4.4],\n",
       "       [4.9, 3. ],\n",
       "       [6.1, 3. ],\n",
       "       [5.4, 3. ],\n",
       "       [5.1, 3.8],\n",
       "       [6. , 3.4],\n",
       "       [5.2, 2.7],\n",
       "       [7.7, 3.8],\n",
       "       [6.1, 2.6],\n",
       "       [4.9, 3.1],\n",
       "       [4.8, 3.1],\n",
       "       [7.2, 3.2],\n",
       "       [6.7, 2.5],\n",
       "       [4.6, 3.6]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('iris-versicolor.csv')\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "\n",
    "X = df.iloc[:, 1:3].values\n",
    "Y = df.iloc[:,0].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 2), (38, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain.shape, xTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(self, X, Y):\n",
    "\n",
    "\t\tres = []\n",
    "\t\tfor x, y in zip(X, Y):\n",
    "\t\t\t_, pred = self.predict(x)\n",
    "\t\t\tres.append(pred)\n",
    "\n",
    "\t\treturn mean_squared_error(Y, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FuzzyMMC(sensitivity=1, exp_bound=0.1, animate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.631578947368421"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(xTest, yTest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3684210526315789"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mean_squared_error(xTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 0.75], 1.0, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = xTest[9]\n",
    "\n",
    "membership, max_memb, pred = model.predict(x)\n",
    "(membership, max_memb, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTest[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange (0.0, 1.1, 0.1)\n",
    "parameters = {'sensitivity': a, 'exp_bound': a }\n",
    "parameters['exp_bound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(model, parameters, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rita folisi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=<fuzzy.FuzzyMMC object at 0x0000027FCF157E88>,\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'exp_bound': array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       "                         'sensitivity': array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.12113981, 0.23228436, 0.20704122, 0.15728297, 0.14175529,\n",
       "        0.18534212, 0.19645467, 0.17693205, 0.15889106, 0.13116846,\n",
       "        0.12365913, 0.14391785, 0.13415513, 0.07640142, 0.07184992,\n",
       "        0.06948714, 0.06943793, 0.07299733, 0.06774464, 0.0721097 ,\n",
       "        0.07090912, 0.07731051, 0.05578303, 0.04686046, 0.04827118,\n",
       "        0.04747915, 0.05167847, 0.04997606, 0.04766684, 0.04897103,\n",
       "        0.05009036, 0.06353464, 0.07615585, 0.06596847, 0.06123466,\n",
       "        0.0544539 , 0.04287882, 0.03715558, 0.03591537, 0.03626761,\n",
       "        0.03273034, 0.03490124, 0.0369081 , 0.04767184, 0.03929491,\n",
       "        0.0385437 , 0.03829813, 0.04012251, 0.03231316, 0.02413554,\n",
       "        0.02632847, 0.04478555, 0.02713346, 0.02314448, 0.02432675,\n",
       "        0.02687864, 0.02300506, 0.02255106, 0.02214046, 0.02274518,\n",
       "        0.02474766, 0.02193122, 0.0211494 , 0.02114286, 0.02253799,\n",
       "        0.02114882, 0.02259626, 0.01884627, 0.01735296, 0.01695461,\n",
       "        0.0177608 , 0.01836171, 0.01954241, 0.0181571 , 0.01854467,\n",
       "        0.01825457, 0.01908646, 0.02254047, 0.01901493, 0.0200706 ,\n",
       "        0.02016873, 0.01937428, 0.01845193, 0.01838636, 0.01772904,\n",
       "        0.02015696, 0.02982335, 0.01835012, 0.02134275, 0.01755352,\n",
       "        0.01815171, 0.01595721, 0.01615729, 0.01894927, 0.01755314,\n",
       "        0.01644678, 0.01581826, 0.01665497, 0.01555247, 0.01595006,\n",
       "        0.01555481, 0.01794624, 0.01375794, 0.01454802, 0.01476216,\n",
       "        0.01415057, 0.01694975, 0.01705718, 0.0167974 , 0.01661849,\n",
       "        0.015837  , 0.0167552 , 0.01728201, 0.01574736, 0.01526942,\n",
       "        0.01527233, 0.01482019, 0.01628785, 0.01476026, 0.01616507,\n",
       "        0.01555362]),\n",
       " 'std_fit_time': array([0.00795721, 0.025119  , 0.04743836, 0.00513884, 0.00647818,\n",
       "        0.0300996 , 0.04925271, 0.02232109, 0.03082645, 0.004597  ,\n",
       "        0.00788912, 0.07240547, 0.01242298, 0.0065538 , 0.0062864 ,\n",
       "        0.00241858, 0.00521751, 0.00548355, 0.00276584, 0.00465934,\n",
       "        0.00709177, 0.01338078, 0.00347823, 0.00284233, 0.00102325,\n",
       "        0.00312155, 0.00545623, 0.00209763, 0.00292532, 0.00388538,\n",
       "        0.00291345, 0.01597308, 0.00961091, 0.00425583, 0.00331467,\n",
       "        0.01385633, 0.00496554, 0.00217852, 0.00362288, 0.00245152,\n",
       "        0.00299536, 0.00598974, 0.00582668, 0.02041367, 0.00941159,\n",
       "        0.00384686, 0.00573265, 0.00674834, 0.00745219, 0.0025544 ,\n",
       "        0.00195434, 0.01753437, 0.00460515, 0.00172081, 0.00343667,\n",
       "        0.00315462, 0.00289407, 0.00162298, 0.00203439, 0.00169695,\n",
       "        0.00145366, 0.00209171, 0.00231511, 0.00133759, 0.00203964,\n",
       "        0.0031768 , 0.00258169, 0.00434777, 0.00205425, 0.00109258,\n",
       "        0.00213079, 0.00224829, 0.0038792 , 0.00170599, 0.00241489,\n",
       "        0.00172332, 0.00176031, 0.00982799, 0.00321037, 0.00324522,\n",
       "        0.00342247, 0.00259515, 0.00359354, 0.00242176, 0.00255179,\n",
       "        0.00364732, 0.01091492, 0.0010167 , 0.00522422, 0.00421255,\n",
       "        0.00213048, 0.00260153, 0.00247559, 0.00302521, 0.00205309,\n",
       "        0.00173744, 0.00162635, 0.00146789, 0.00100738, 0.00109441,\n",
       "        0.00049138, 0.00432377, 0.00095759, 0.00101848, 0.00262909,\n",
       "        0.00146719, 0.00165515, 0.00233371, 0.00199352, 0.0034433 ,\n",
       "        0.00128731, 0.00317915, 0.00233273, 0.00116287, 0.00171107,\n",
       "        0.001591  , 0.00299908, 0.00285995, 0.00074717, 0.00192903,\n",
       "        0.00259025]),\n",
       " 'mean_score_time': array([0.002387  , 0.00658202, 0.00419464, 0.0033967 , 0.00438738,\n",
       "        0.00521398, 0.00359755, 0.00339036, 0.00299244, 0.00319538,\n",
       "        0.00280533, 0.00598979, 0.0035903 , 0.00258756, 0.0027    ,\n",
       "        0.00218782, 0.0023921 , 0.00219455, 0.00298829, 0.00259805,\n",
       "        0.00259371, 0.00279865, 0.00256906, 0.00260592, 0.00258713,\n",
       "        0.00319295, 0.00259833, 0.00259228, 0.00259252, 0.0029923 ,\n",
       "        0.002984  , 0.00299058, 0.0035902 , 0.00379004, 0.00438919,\n",
       "        0.00418892, 0.00379043, 0.00259256, 0.00238247, 0.00239425,\n",
       "        0.00278959, 0.00199594, 0.00218773, 0.00299234, 0.00259318,\n",
       "        0.00498843, 0.00378981, 0.00336118, 0.0031918 , 0.00299215,\n",
       "        0.00339174, 0.00268798, 0.00239501, 0.00238781, 0.00280018,\n",
       "        0.00259905, 0.00277963, 0.00238237, 0.00285668, 0.00278664,\n",
       "        0.00357637, 0.00220437, 0.00239358, 0.00258713, 0.00279479,\n",
       "        0.00338497, 0.0021945 , 0.00319228, 0.00279856, 0.00259356,\n",
       "        0.00258412, 0.00218358, 0.00239911, 0.0023931 , 0.00240517,\n",
       "        0.00238752, 0.00320182, 0.00199389, 0.0024004 , 0.00300221,\n",
       "        0.00217767, 0.00298553, 0.00260143, 0.0025506 , 0.00242338,\n",
       "        0.00257554, 0.00359063, 0.00239434, 0.00239367, 0.00299153,\n",
       "        0.0027926 , 0.00259318, 0.00219355, 0.00219431, 0.00279284,\n",
       "        0.00259328, 0.0021874 , 0.00220356, 0.00200124, 0.00218792,\n",
       "        0.0029902 , 0.00219955, 0.00200047, 0.00280452, 0.00198774,\n",
       "        0.00320301, 0.00199971, 0.00259328, 0.00219955, 0.00278649,\n",
       "        0.00291214, 0.0027926 , 0.00218186, 0.00239849, 0.0019927 ,\n",
       "        0.00200062, 0.00319009, 0.00279269, 0.00238824, 0.002385  ,\n",
       "        0.00239286]),\n",
       " 'std_score_time': array([4.94467796e-04, 2.32685973e-03, 9.76503913e-04, 4.83384844e-04,\n",
       "        1.34848596e-03, 9.72750432e-04, 1.00978732e-03, 4.88577796e-04,\n",
       "        7.29420592e-07, 3.83114654e-04, 7.41624030e-04, 2.88600421e-03,\n",
       "        1.84993083e-03, 4.95406706e-04, 4.00832322e-04, 7.46889276e-04,\n",
       "        5.01321186e-04, 3.99279776e-04, 6.22585689e-04, 4.92146516e-04,\n",
       "        4.89357311e-04, 4.01720310e-04, 1.36433163e-03, 4.87622757e-04,\n",
       "        4.84393036e-04, 1.16322785e-03, 4.91669206e-04, 7.97069195e-04,\n",
       "        4.88383485e-04, 1.09237421e-03, 6.22364279e-04, 1.09241075e-03,\n",
       "        1.73903026e-03, 7.45501045e-04, 1.01743955e-03, 9.76376667e-04,\n",
       "        1.32306760e-03, 4.88617551e-04, 4.98801284e-04, 7.91042398e-04,\n",
       "        7.39509938e-04, 1.86434182e-05, 3.86361144e-04, 8.92336595e-04,\n",
       "        1.35272589e-03, 1.26319950e-03, 9.77603101e-04, 7.36022511e-04,\n",
       "        1.16231966e-03, 1.26233151e-03, 1.84945321e-03, 7.47899381e-04,\n",
       "        4.76487308e-04, 1.02014241e-03, 7.39594529e-04, 9.96160145e-04,\n",
       "        7.51615478e-04, 4.87062925e-04, 7.74845378e-04, 9.83041210e-04,\n",
       "        2.24526026e-03, 3.93449299e-04, 7.97880086e-04, 8.03577184e-04,\n",
       "        1.16340821e-03, 1.18562871e-03, 3.98707486e-04, 1.46924015e-03,\n",
       "        7.55493561e-04, 7.98130976e-04, 7.82240954e-04, 7.41994022e-04,\n",
       "        4.84908519e-04, 4.88620636e-04, 4.79168865e-04, 8.00904753e-04,\n",
       "        9.69382507e-04, 6.30374232e-04, 4.83440995e-04, 1.08706883e-03,\n",
       "        4.08464549e-04, 6.30880220e-04, 7.93133903e-04, 4.82477730e-04,\n",
       "        8.01101690e-04, 4.87123328e-04, 1.01727995e-03, 4.88889342e-04,\n",
       "        4.88753142e-04, 8.92283392e-04, 7.45780084e-04, 7.98475954e-04,\n",
       "        3.98707714e-04, 3.99995458e-04, 1.16376704e-03, 1.19650374e-03,\n",
       "        4.02208245e-04, 3.92346256e-04, 1.35058601e-05, 3.89242537e-04,\n",
       "        6.31214031e-04, 3.96021186e-04, 1.02410147e-05, 7.42332654e-04,\n",
       "        6.19803595e-04, 1.16228579e-03, 1.19586348e-05, 4.88652241e-04,\n",
       "        3.97412136e-04, 1.33064500e-03, 8.25334813e-04, 7.45589311e-04,\n",
       "        4.04175051e-04, 1.01465577e-03, 1.84431835e-05, 1.08802496e-05,\n",
       "        1.46608860e-03, 7.53284798e-04, 7.87139753e-04, 4.84931917e-04,\n",
       "        1.01205272e-03]),\n",
       " 'param_exp_bound': masked_array(data=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.6000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, 1.0, 1.0, 1.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_sensitivity': masked_array(data=[0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 1.0,\n",
       "                    0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 1.0,\n",
       "                    0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 1.0,\n",
       "                    0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 1.0,\n",
       "                    0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 1.0,\n",
       "                    0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 1.0,\n",
       "                    0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 1.0,\n",
       "                    0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 1.0,\n",
       "                    0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 1.0,\n",
       "                    0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 1.0,\n",
       "                    0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 1.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'exp_bound': 0.0, 'sensitivity': 0.0},\n",
       "  {'exp_bound': 0.0, 'sensitivity': 0.1},\n",
       "  {'exp_bound': 0.0, 'sensitivity': 0.2},\n",
       "  {'exp_bound': 0.0, 'sensitivity': 0.30000000000000004},\n",
       "  {'exp_bound': 0.0, 'sensitivity': 0.4},\n",
       "  {'exp_bound': 0.0, 'sensitivity': 0.5},\n",
       "  {'exp_bound': 0.0, 'sensitivity': 0.6000000000000001},\n",
       "  {'exp_bound': 0.0, 'sensitivity': 0.7000000000000001},\n",
       "  {'exp_bound': 0.0, 'sensitivity': 0.8},\n",
       "  {'exp_bound': 0.0, 'sensitivity': 0.9},\n",
       "  {'exp_bound': 0.0, 'sensitivity': 1.0},\n",
       "  {'exp_bound': 0.1, 'sensitivity': 0.0},\n",
       "  {'exp_bound': 0.1, 'sensitivity': 0.1},\n",
       "  {'exp_bound': 0.1, 'sensitivity': 0.2},\n",
       "  {'exp_bound': 0.1, 'sensitivity': 0.30000000000000004},\n",
       "  {'exp_bound': 0.1, 'sensitivity': 0.4},\n",
       "  {'exp_bound': 0.1, 'sensitivity': 0.5},\n",
       "  {'exp_bound': 0.1, 'sensitivity': 0.6000000000000001},\n",
       "  {'exp_bound': 0.1, 'sensitivity': 0.7000000000000001},\n",
       "  {'exp_bound': 0.1, 'sensitivity': 0.8},\n",
       "  {'exp_bound': 0.1, 'sensitivity': 0.9},\n",
       "  {'exp_bound': 0.1, 'sensitivity': 1.0},\n",
       "  {'exp_bound': 0.2, 'sensitivity': 0.0},\n",
       "  {'exp_bound': 0.2, 'sensitivity': 0.1},\n",
       "  {'exp_bound': 0.2, 'sensitivity': 0.2},\n",
       "  {'exp_bound': 0.2, 'sensitivity': 0.30000000000000004},\n",
       "  {'exp_bound': 0.2, 'sensitivity': 0.4},\n",
       "  {'exp_bound': 0.2, 'sensitivity': 0.5},\n",
       "  {'exp_bound': 0.2, 'sensitivity': 0.6000000000000001},\n",
       "  {'exp_bound': 0.2, 'sensitivity': 0.7000000000000001},\n",
       "  {'exp_bound': 0.2, 'sensitivity': 0.8},\n",
       "  {'exp_bound': 0.2, 'sensitivity': 0.9},\n",
       "  {'exp_bound': 0.2, 'sensitivity': 1.0},\n",
       "  {'exp_bound': 0.30000000000000004, 'sensitivity': 0.0},\n",
       "  {'exp_bound': 0.30000000000000004, 'sensitivity': 0.1},\n",
       "  {'exp_bound': 0.30000000000000004, 'sensitivity': 0.2},\n",
       "  {'exp_bound': 0.30000000000000004, 'sensitivity': 0.30000000000000004},\n",
       "  {'exp_bound': 0.30000000000000004, 'sensitivity': 0.4},\n",
       "  {'exp_bound': 0.30000000000000004, 'sensitivity': 0.5},\n",
       "  {'exp_bound': 0.30000000000000004, 'sensitivity': 0.6000000000000001},\n",
       "  {'exp_bound': 0.30000000000000004, 'sensitivity': 0.7000000000000001},\n",
       "  {'exp_bound': 0.30000000000000004, 'sensitivity': 0.8},\n",
       "  {'exp_bound': 0.30000000000000004, 'sensitivity': 0.9},\n",
       "  {'exp_bound': 0.30000000000000004, 'sensitivity': 1.0},\n",
       "  {'exp_bound': 0.4, 'sensitivity': 0.0},\n",
       "  {'exp_bound': 0.4, 'sensitivity': 0.1},\n",
       "  {'exp_bound': 0.4, 'sensitivity': 0.2},\n",
       "  {'exp_bound': 0.4, 'sensitivity': 0.30000000000000004},\n",
       "  {'exp_bound': 0.4, 'sensitivity': 0.4},\n",
       "  {'exp_bound': 0.4, 'sensitivity': 0.5},\n",
       "  {'exp_bound': 0.4, 'sensitivity': 0.6000000000000001},\n",
       "  {'exp_bound': 0.4, 'sensitivity': 0.7000000000000001},\n",
       "  {'exp_bound': 0.4, 'sensitivity': 0.8},\n",
       "  {'exp_bound': 0.4, 'sensitivity': 0.9},\n",
       "  {'exp_bound': 0.4, 'sensitivity': 1.0},\n",
       "  {'exp_bound': 0.5, 'sensitivity': 0.0},\n",
       "  {'exp_bound': 0.5, 'sensitivity': 0.1},\n",
       "  {'exp_bound': 0.5, 'sensitivity': 0.2},\n",
       "  {'exp_bound': 0.5, 'sensitivity': 0.30000000000000004},\n",
       "  {'exp_bound': 0.5, 'sensitivity': 0.4},\n",
       "  {'exp_bound': 0.5, 'sensitivity': 0.5},\n",
       "  {'exp_bound': 0.5, 'sensitivity': 0.6000000000000001},\n",
       "  {'exp_bound': 0.5, 'sensitivity': 0.7000000000000001},\n",
       "  {'exp_bound': 0.5, 'sensitivity': 0.8},\n",
       "  {'exp_bound': 0.5, 'sensitivity': 0.9},\n",
       "  {'exp_bound': 0.5, 'sensitivity': 1.0},\n",
       "  {'exp_bound': 0.6000000000000001, 'sensitivity': 0.0},\n",
       "  {'exp_bound': 0.6000000000000001, 'sensitivity': 0.1},\n",
       "  {'exp_bound': 0.6000000000000001, 'sensitivity': 0.2},\n",
       "  {'exp_bound': 0.6000000000000001, 'sensitivity': 0.30000000000000004},\n",
       "  {'exp_bound': 0.6000000000000001, 'sensitivity': 0.4},\n",
       "  {'exp_bound': 0.6000000000000001, 'sensitivity': 0.5},\n",
       "  {'exp_bound': 0.6000000000000001, 'sensitivity': 0.6000000000000001},\n",
       "  {'exp_bound': 0.6000000000000001, 'sensitivity': 0.7000000000000001},\n",
       "  {'exp_bound': 0.6000000000000001, 'sensitivity': 0.8},\n",
       "  {'exp_bound': 0.6000000000000001, 'sensitivity': 0.9},\n",
       "  {'exp_bound': 0.6000000000000001, 'sensitivity': 1.0},\n",
       "  {'exp_bound': 0.7000000000000001, 'sensitivity': 0.0},\n",
       "  {'exp_bound': 0.7000000000000001, 'sensitivity': 0.1},\n",
       "  {'exp_bound': 0.7000000000000001, 'sensitivity': 0.2},\n",
       "  {'exp_bound': 0.7000000000000001, 'sensitivity': 0.30000000000000004},\n",
       "  {'exp_bound': 0.7000000000000001, 'sensitivity': 0.4},\n",
       "  {'exp_bound': 0.7000000000000001, 'sensitivity': 0.5},\n",
       "  {'exp_bound': 0.7000000000000001, 'sensitivity': 0.6000000000000001},\n",
       "  {'exp_bound': 0.7000000000000001, 'sensitivity': 0.7000000000000001},\n",
       "  {'exp_bound': 0.7000000000000001, 'sensitivity': 0.8},\n",
       "  {'exp_bound': 0.7000000000000001, 'sensitivity': 0.9},\n",
       "  {'exp_bound': 0.7000000000000001, 'sensitivity': 1.0},\n",
       "  {'exp_bound': 0.8, 'sensitivity': 0.0},\n",
       "  {'exp_bound': 0.8, 'sensitivity': 0.1},\n",
       "  {'exp_bound': 0.8, 'sensitivity': 0.2},\n",
       "  {'exp_bound': 0.8, 'sensitivity': 0.30000000000000004},\n",
       "  {'exp_bound': 0.8, 'sensitivity': 0.4},\n",
       "  {'exp_bound': 0.8, 'sensitivity': 0.5},\n",
       "  {'exp_bound': 0.8, 'sensitivity': 0.6000000000000001},\n",
       "  {'exp_bound': 0.8, 'sensitivity': 0.7000000000000001},\n",
       "  {'exp_bound': 0.8, 'sensitivity': 0.8},\n",
       "  {'exp_bound': 0.8, 'sensitivity': 0.9},\n",
       "  {'exp_bound': 0.8, 'sensitivity': 1.0},\n",
       "  {'exp_bound': 0.9, 'sensitivity': 0.0},\n",
       "  {'exp_bound': 0.9, 'sensitivity': 0.1},\n",
       "  {'exp_bound': 0.9, 'sensitivity': 0.2},\n",
       "  {'exp_bound': 0.9, 'sensitivity': 0.30000000000000004},\n",
       "  {'exp_bound': 0.9, 'sensitivity': 0.4},\n",
       "  {'exp_bound': 0.9, 'sensitivity': 0.5},\n",
       "  {'exp_bound': 0.9, 'sensitivity': 0.6000000000000001},\n",
       "  {'exp_bound': 0.9, 'sensitivity': 0.7000000000000001},\n",
       "  {'exp_bound': 0.9, 'sensitivity': 0.8},\n",
       "  {'exp_bound': 0.9, 'sensitivity': 0.9},\n",
       "  {'exp_bound': 0.9, 'sensitivity': 1.0},\n",
       "  {'exp_bound': 1.0, 'sensitivity': 0.0},\n",
       "  {'exp_bound': 1.0, 'sensitivity': 0.1},\n",
       "  {'exp_bound': 1.0, 'sensitivity': 0.2},\n",
       "  {'exp_bound': 1.0, 'sensitivity': 0.30000000000000004},\n",
       "  {'exp_bound': 1.0, 'sensitivity': 0.4},\n",
       "  {'exp_bound': 1.0, 'sensitivity': 0.5},\n",
       "  {'exp_bound': 1.0, 'sensitivity': 0.6000000000000001},\n",
       "  {'exp_bound': 1.0, 'sensitivity': 0.7000000000000001},\n",
       "  {'exp_bound': 1.0, 'sensitivity': 0.8},\n",
       "  {'exp_bound': 1.0, 'sensitivity': 0.9},\n",
       "  {'exp_bound': 1.0, 'sensitivity': 1.0}],\n",
       " 'split0_test_score': array([0.60869565, 0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 ,\n",
       "        0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 ,\n",
       "        0.7826087 , 0.60869565, 0.69565217, 0.69565217, 0.73913043,\n",
       "        0.69565217, 0.73913043, 0.73913043, 0.73913043, 0.73913043,\n",
       "        0.73913043, 0.73913043, 0.60869565, 0.7826087 , 0.7826087 ,\n",
       "        0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 ,\n",
       "        0.7826087 , 0.7826087 , 0.7826087 , 0.60869565, 0.82608696,\n",
       "        0.82608696, 0.82608696, 0.82608696, 0.82608696, 0.82608696,\n",
       "        0.82608696, 0.82608696, 0.82608696, 0.82608696, 0.60869565,\n",
       "        0.69565217, 0.69565217, 0.69565217, 0.69565217, 0.69565217,\n",
       "        0.69565217, 0.69565217, 0.69565217, 0.69565217, 0.69565217,\n",
       "        0.60869565, 0.82608696, 0.82608696, 0.82608696, 0.82608696,\n",
       "        0.82608696, 0.82608696, 0.82608696, 0.69565217, 0.82608696,\n",
       "        0.82608696, 0.60869565, 0.86956522, 0.86956522, 0.86956522,\n",
       "        0.86956522, 0.86956522, 0.86956522, 0.86956522, 0.86956522,\n",
       "        0.86956522, 0.86956522, 0.60869565, 0.86956522, 0.86956522,\n",
       "        0.86956522, 0.86956522, 0.86956522, 0.86956522, 0.86956522,\n",
       "        0.86956522, 0.86956522, 0.86956522, 0.60869565, 0.69565217,\n",
       "        0.69565217, 0.69565217, 0.69565217, 0.69565217, 0.69565217,\n",
       "        0.69565217, 0.69565217, 0.69565217, 0.69565217, 0.60869565,\n",
       "        0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 ,\n",
       "        0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 ,\n",
       "        0.60869565, 0.73913043, 0.73913043, 0.73913043, 0.73913043,\n",
       "        0.73913043, 0.73913043, 0.73913043, 0.73913043, 0.73913043,\n",
       "        0.73913043]),\n",
       " 'split1_test_score': array([0.65217391, 0.65217391, 0.65217391, 0.65217391, 0.65217391,\n",
       "        0.65217391, 0.65217391, 0.65217391, 0.65217391, 0.65217391,\n",
       "        0.65217391, 0.65217391, 0.56521739, 0.56521739, 0.60869565,\n",
       "        0.56521739, 0.60869565, 0.60869565, 0.60869565, 0.60869565,\n",
       "        0.60869565, 0.60869565, 0.65217391, 0.56521739, 0.56521739,\n",
       "        0.56521739, 0.56521739, 0.56521739, 0.56521739, 0.56521739,\n",
       "        0.56521739, 0.56521739, 0.56521739, 0.65217391, 0.65217391,\n",
       "        0.65217391, 0.65217391, 0.65217391, 0.65217391, 0.65217391,\n",
       "        0.65217391, 0.65217391, 0.65217391, 0.65217391, 0.65217391,\n",
       "        0.56521739, 0.56521739, 0.56521739, 0.56521739, 0.56521739,\n",
       "        0.56521739, 0.56521739, 0.56521739, 0.56521739, 0.56521739,\n",
       "        0.65217391, 0.69565217, 0.69565217, 0.69565217, 0.69565217,\n",
       "        0.69565217, 0.69565217, 0.69565217, 0.69565217, 0.69565217,\n",
       "        0.69565217, 0.65217391, 0.69565217, 0.69565217, 0.69565217,\n",
       "        0.69565217, 0.56521739, 0.56521739, 0.69565217, 0.56521739,\n",
       "        0.56521739, 0.56521739, 0.65217391, 0.82608696, 0.82608696,\n",
       "        0.7826087 , 0.82608696, 0.82608696, 0.82608696, 0.7826087 ,\n",
       "        0.82608696, 0.82608696, 0.82608696, 0.65217391, 0.73913043,\n",
       "        0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 ,\n",
       "        0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 , 0.65217391,\n",
       "        0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 ,\n",
       "        0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 ,\n",
       "        0.65217391, 0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 ,\n",
       "        0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 ,\n",
       "        0.7826087 ]),\n",
       " 'split2_test_score': array([0.59090909, 0.59090909, 0.59090909, 0.59090909, 0.59090909,\n",
       "        0.59090909, 0.59090909, 0.59090909, 0.59090909, 0.59090909,\n",
       "        0.59090909, 0.59090909, 0.59090909, 0.59090909, 0.59090909,\n",
       "        0.59090909, 0.59090909, 0.59090909, 0.59090909, 0.59090909,\n",
       "        0.59090909, 0.59090909, 0.59090909, 0.68181818, 0.68181818,\n",
       "        0.68181818, 0.68181818, 0.68181818, 0.68181818, 0.68181818,\n",
       "        0.68181818, 0.68181818, 0.68181818, 0.59090909, 0.63636364,\n",
       "        0.63636364, 0.63636364, 0.63636364, 0.63636364, 0.63636364,\n",
       "        0.63636364, 0.63636364, 0.63636364, 0.63636364, 0.59090909,\n",
       "        0.59090909, 0.59090909, 0.59090909, 0.59090909, 0.59090909,\n",
       "        0.59090909, 0.59090909, 0.59090909, 0.59090909, 0.59090909,\n",
       "        0.59090909, 0.72727273, 0.72727273, 0.81818182, 0.72727273,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.81818182, 0.81818182,\n",
       "        0.81818182, 0.59090909, 0.72727273, 0.72727273, 0.72727273,\n",
       "        0.72727273, 0.72727273, 0.72727273, 0.72727273, 0.72727273,\n",
       "        0.72727273, 0.72727273, 0.59090909, 0.59090909, 0.59090909,\n",
       "        0.59090909, 0.59090909, 0.59090909, 0.59090909, 0.59090909,\n",
       "        0.59090909, 0.59090909, 0.59090909, 0.59090909, 0.68181818,\n",
       "        0.68181818, 0.68181818, 0.68181818, 0.68181818, 0.68181818,\n",
       "        0.68181818, 0.68181818, 0.68181818, 0.68181818, 0.59090909,\n",
       "        0.72727273, 0.72727273, 0.72727273, 0.72727273, 0.72727273,\n",
       "        0.72727273, 0.72727273, 0.72727273, 0.72727273, 0.72727273,\n",
       "        0.59090909, 0.81818182, 0.81818182, 0.81818182, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.81818182, 0.81818182,\n",
       "        0.81818182]),\n",
       " 'split3_test_score': array([0.63636364, 0.68181818, 0.68181818, 0.68181818, 0.68181818,\n",
       "        0.68181818, 0.68181818, 0.68181818, 0.68181818, 0.68181818,\n",
       "        0.68181818, 0.63636364, 0.68181818, 0.68181818, 0.68181818,\n",
       "        0.68181818, 0.68181818, 0.68181818, 0.68181818, 0.68181818,\n",
       "        0.68181818, 0.68181818, 0.63636364, 0.81818182, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.81818182, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.63636364, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.81818182, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.81818182, 0.63636364,\n",
       "        0.72727273, 0.72727273, 0.72727273, 0.72727273, 0.72727273,\n",
       "        0.72727273, 0.72727273, 0.72727273, 0.72727273, 0.72727273,\n",
       "        0.63636364, 0.77272727, 0.77272727, 0.77272727, 0.77272727,\n",
       "        0.77272727, 0.77272727, 0.77272727, 0.77272727, 0.77272727,\n",
       "        0.77272727, 0.63636364, 0.81818182, 0.81818182, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.81818182, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.63636364, 0.81818182, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.81818182, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.63636364, 0.77272727,\n",
       "        0.77272727, 0.77272727, 0.77272727, 0.77272727, 0.77272727,\n",
       "        0.77272727, 0.77272727, 0.77272727, 0.77272727, 0.63636364,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.81818182, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.81818182, 0.81818182,\n",
       "        0.63636364, 0.72727273, 0.72727273, 0.72727273, 0.72727273,\n",
       "        0.72727273, 0.72727273, 0.72727273, 0.72727273, 0.72727273,\n",
       "        0.72727273]),\n",
       " 'split4_test_score': array([0.68181818, 0.77272727, 0.77272727, 0.72727273, 0.81818182,\n",
       "        0.72727273, 0.72727273, 0.72727273, 0.72727273, 0.72727273,\n",
       "        0.72727273, 0.68181818, 0.72727273, 0.72727273, 0.68181818,\n",
       "        0.72727273, 0.68181818, 0.68181818, 0.68181818, 0.68181818,\n",
       "        0.68181818, 0.68181818, 0.68181818, 0.59090909, 0.59090909,\n",
       "        0.59090909, 0.59090909, 0.59090909, 0.59090909, 0.59090909,\n",
       "        0.59090909, 0.59090909, 0.59090909, 0.68181818, 0.77272727,\n",
       "        0.77272727, 0.77272727, 0.77272727, 0.77272727, 0.77272727,\n",
       "        0.77272727, 0.77272727, 0.77272727, 0.77272727, 0.68181818,\n",
       "        0.63636364, 0.63636364, 0.63636364, 0.63636364, 0.63636364,\n",
       "        0.63636364, 0.63636364, 0.63636364, 0.63636364, 0.63636364,\n",
       "        0.68181818, 0.72727273, 0.72727273, 0.72727273, 0.72727273,\n",
       "        0.72727273, 0.72727273, 0.72727273, 0.72727273, 0.72727273,\n",
       "        0.72727273, 0.68181818, 0.54545455, 0.54545455, 0.54545455,\n",
       "        0.54545455, 0.54545455, 0.54545455, 0.54545455, 0.54545455,\n",
       "        0.54545455, 0.54545455, 0.68181818, 0.59090909, 0.59090909,\n",
       "        0.59090909, 0.59090909, 0.59090909, 0.59090909, 0.59090909,\n",
       "        0.59090909, 0.59090909, 0.59090909, 0.68181818, 0.72727273,\n",
       "        0.72727273, 0.72727273, 0.72727273, 0.72727273, 0.72727273,\n",
       "        0.72727273, 0.72727273, 0.72727273, 0.72727273, 0.68181818,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.81818182, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.81818182, 0.81818182,\n",
       "        0.68181818, 0.59090909, 0.59090909, 0.59090909, 0.59090909,\n",
       "        0.59090909, 0.59090909, 0.59090909, 0.59090909, 0.59090909,\n",
       "        0.59090909]),\n",
       " 'mean_test_score': array([0.63392857, 0.69642857, 0.69642857, 0.6875    , 0.70535714,\n",
       "        0.6875    , 0.6875    , 0.6875    , 0.6875    , 0.6875    ,\n",
       "        0.6875    , 0.63392857, 0.65178571, 0.65178571, 0.66071429,\n",
       "        0.65178571, 0.66071429, 0.66071429, 0.66071429, 0.66071429,\n",
       "        0.66071429, 0.66071429, 0.63392857, 0.6875    , 0.6875    ,\n",
       "        0.6875    , 0.6875    , 0.6875    , 0.6875    , 0.6875    ,\n",
       "        0.6875    , 0.6875    , 0.6875    , 0.63392857, 0.74107143,\n",
       "        0.74107143, 0.74107143, 0.74107143, 0.74107143, 0.74107143,\n",
       "        0.74107143, 0.74107143, 0.74107143, 0.74107143, 0.63392857,\n",
       "        0.64285714, 0.64285714, 0.64285714, 0.64285714, 0.64285714,\n",
       "        0.64285714, 0.64285714, 0.64285714, 0.64285714, 0.64285714,\n",
       "        0.63392857, 0.75      , 0.75      , 0.76785714, 0.75      ,\n",
       "        0.76785714, 0.76785714, 0.76785714, 0.74107143, 0.76785714,\n",
       "        0.76785714, 0.63392857, 0.73214286, 0.73214286, 0.73214286,\n",
       "        0.73214286, 0.70535714, 0.70535714, 0.73214286, 0.70535714,\n",
       "        0.70535714, 0.70535714, 0.63392857, 0.74107143, 0.74107143,\n",
       "        0.73214286, 0.74107143, 0.74107143, 0.74107143, 0.73214286,\n",
       "        0.74107143, 0.74107143, 0.74107143, 0.63392857, 0.72321429,\n",
       "        0.73214286, 0.73214286, 0.73214286, 0.73214286, 0.73214286,\n",
       "        0.73214286, 0.73214286, 0.73214286, 0.73214286, 0.63392857,\n",
       "        0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
       "        0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
       "        0.63392857, 0.73214286, 0.73214286, 0.73214286, 0.73214286,\n",
       "        0.73214286, 0.73214286, 0.73214286, 0.73214286, 0.73214286,\n",
       "        0.73214286]),\n",
       " 'std_test_score': array([0.031848  , 0.07280056, 0.07280056, 0.06529601, 0.08359739,\n",
       "        0.06529601, 0.06529601, 0.06529601, 0.06529601, 0.06529601,\n",
       "        0.06529601, 0.031848  , 0.06291706, 0.06291706, 0.05431908,\n",
       "        0.06291706, 0.05431908, 0.05431908, 0.05431908, 0.05431908,\n",
       "        0.05431908, 0.05431908, 0.031848  , 0.10060736, 0.10060736,\n",
       "        0.10060736, 0.10060736, 0.10060736, 0.10060736, 0.10060736,\n",
       "        0.10060736, 0.10060736, 0.10060736, 0.031848  , 0.08139737,\n",
       "        0.08139737, 0.08139737, 0.08139737, 0.08139737, 0.08139737,\n",
       "        0.08139737, 0.08139737, 0.08139737, 0.08139737, 0.031848  ,\n",
       "        0.06122407, 0.06122407, 0.06122407, 0.06122407, 0.06122407,\n",
       "        0.06122407, 0.06122407, 0.06122407, 0.06122407, 0.06122407,\n",
       "        0.031848  , 0.0458236 , 0.0458236 , 0.05091771, 0.0458236 ,\n",
       "        0.05091771, 0.05091771, 0.05091771, 0.04742861, 0.05091771,\n",
       "        0.05091771, 0.031848  , 0.1116082 , 0.1116082 , 0.1116082 ,\n",
       "        0.1116082 , 0.13110135, 0.13110135, 0.1116082 , 0.13110135,\n",
       "        0.13110135, 0.13110135, 0.031848  , 0.12207057, 0.12207057,\n",
       "        0.11701098, 0.12207057, 0.12207057, 0.12207057, 0.11701098,\n",
       "        0.12207057, 0.12207057, 0.12207057, 0.031848  , 0.03208457,\n",
       "        0.0402755 , 0.0402755 , 0.0402755 , 0.0402755 , 0.0402755 ,\n",
       "        0.0402755 , 0.0402755 , 0.0402755 , 0.0402755 , 0.031848  ,\n",
       "        0.03299959, 0.03299959, 0.03299959, 0.03299959, 0.03299959,\n",
       "        0.03299959, 0.03299959, 0.03299959, 0.03299959, 0.03299959,\n",
       "        0.031848  , 0.07687619, 0.07687619, 0.07687619, 0.07687619,\n",
       "        0.07687619, 0.07687619, 0.07687619, 0.07687619, 0.07687619,\n",
       "        0.07687619]),\n",
       " 'rank_test_score': array([111,  72,  72,  74,  66,  74,  74,  74,  74,  74,  74, 111,  98,\n",
       "         98,  91,  98,  91,  91,  91,  91,  91,  91, 111,  74,  74,  74,\n",
       "         74,  74,  74,  74,  74,  74,  74, 111,  20,  20,  20,  20,  20,\n",
       "         20,  20,  20,  20,  20, 111, 101, 101, 101, 101, 101, 101, 101,\n",
       "        101, 101, 101, 111,  17,  17,  11,  17,  11,  11,  11,  20,  11,\n",
       "         11, 111,  39,  39,  39,  39,  66,  66,  39,  66,  66,  66, 111,\n",
       "         20,  20,  39,  20,  20,  20,  39,  20,  20,  20, 111,  65,  39,\n",
       "         39,  39,  39,  39,  39,  39,  39,  39, 111,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1, 111,  39,  39,  39,  39,  39,  39,\n",
       "         39,  39,  39,  39])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7105263157894737"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(xTest, yTest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9, 0.1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = clf.best_params_\n",
    "new_exp = best_params['exp_bound']\n",
    "new_sensit = best_params['sensitivity']\n",
    "(new_exp, new_sensit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = FuzzyMMC(sensitivity=new_sensit, exp_bound=new_exp, animate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7105263157894737"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(xTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tdef MSE_membership2(self, X, Y):\n",
    "\n",
    "\t\tres = []\n",
    "\t\tfor x, y in zip(X, Y):\n",
    "\t\t\tpred, _, _ = self.predict(x)\n",
    "\t\t\tres.append(pred)\n",
    "\t\tres = np.array(res)\n",
    "\t\treturn res, mean_squared_error(Y, res[:, 1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5706907894736842"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "res, val = MSE_membership2(model, xTest, yTest)\n",
    "val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ho una MSE della membership così alta perché in generale le membership sono molto alte. Quindi pur avendo alta accuratezza, avrò comunque alto MSE delle membership. Vedi sotto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.975, 0.825],\n",
       "       [1.   , 0.95 ],\n",
       "       [0.975, 0.825],\n",
       "       [0.95 , 0.7  ],\n",
       "       [0.95 , 0.75 ],\n",
       "       [1.   , 0.975],\n",
       "       [0.975, 0.825],\n",
       "       [0.9  , 0.975],\n",
       "       [0.975, 0.975],\n",
       "       [0.9  , 0.75 ],\n",
       "       [0.95 , 0.9  ],\n",
       "       [0.975, 0.975],\n",
       "       [0.975, 0.925],\n",
       "       [0.825, 0.9  ],\n",
       "       [0.925, 0.975],\n",
       "       [0.975, 0.925],\n",
       "       [0.975, 0.85 ],\n",
       "       [1.   , 0.95 ],\n",
       "       [0.95 , 1.   ],\n",
       "       [1.   , 0.875],\n",
       "       [1.   , 0.95 ],\n",
       "       [0.975, 0.925],\n",
       "       [0.9  , 0.975],\n",
       "       [0.925, 0.975],\n",
       "       [0.925, 0.775],\n",
       "       [0.95 , 0.925],\n",
       "       [1.   , 0.75 ],\n",
       "       [0.975, 1.   ],\n",
       "       [0.975, 0.95 ],\n",
       "       [0.975, 0.85 ],\n",
       "       [0.95 , 0.9  ],\n",
       "       [0.975, 0.925],\n",
       "       [0.875, 0.9  ],\n",
       "       [0.875, 0.975],\n",
       "       [0.975, 0.75 ],\n",
       "       [1.   , 0.775],\n",
       "       [1.   , 0.9  ],\n",
       "       [0.9  , 0.675]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.975, 0.975, 0.8  , 0.95 , 1.   , 1.   , 0.975, 0.9  , 1.   ,\n",
       "       0.95 , 0.75 , 0.85 , 0.875, 0.975, 0.95 , 0.775, 0.925, 0.85 ,\n",
       "       0.825, 0.75 , 0.75 , 0.85 , 0.975, 0.95 , 0.775, 0.95 , 0.75 ,\n",
       "       0.775, 0.75 , 1.   , 0.95 , 0.9  , 1.   , 0.75 , 0.775, 0.975,\n",
       "       0.975, 0.825])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res [:, 1]    \n",
    "# vettore delle membership di xTest. [:, 1] indica quelle relative all'appartenenza a setosa. \n",
    "# Quindi indica quanto è effettivamente setosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.875, 0.975, 0.975, 0.975, 0.975, 0.95 , 0.95 , 0.975, 0.975,\n",
       "       0.975, 0.9  , 0.95 , 0.975, 0.95 , 1.   , 0.975, 1.   , 0.975,\n",
       "       0.975, 0.95 , 0.975, 1.   , 1.   , 0.925, 0.975, 0.975, 0.95 ,\n",
       "       1.   , 1.   , 0.925, 0.9  , 0.95 , 0.975, 0.95 , 0.925, 0.85 ,\n",
       "       0.9  , 1.   ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res [:, 0]   # indica quanto effettivamente non è setosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
